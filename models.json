{
  "providers": [
    {
      "name": "Mock",
      "displayName": "Mock",
      "base_model_name": "mock",
      "credentials_needed": {},
      "models": [
        {
          "displayName": "Mock Model",
          "submodels": [
            "mock"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 16384,
          "input_cost_per_token": 2.5e-06,
          "output_cost_per_token": 1e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        }
      ]
    },
    {
      "name": "OpenAI",
      "displayName": "OpenAI",
      "base_model_name": "openai",
      "credentials_needed": {
        "api_key": {
          "type": "string",
          "displayName": "Chave de API",
          "description": "Chave de API da OpenAI",
          "required": true
        }
      },
      "models": [
        {
          "displayName": "GPT-4o",
          "submodels": [
            "gpt-4o",
            "gpt-4o-2024-08-06",
            "gpt-4o-2024-05-13",
            "gpt-4o-2024-11-20"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 16384,
          "input_cost_per_token": 2.5e-06,
          "output_cost_per_token": 1e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "GPT-4o mini",
          "submodels": [
            "gpt-4o-mini",
            "gpt-4o-mini-2024-07-18",
            "gpt-4o-mini-2024-08-06",
            "gpt-4o-mini-2024-05-13"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 16384,
          "input_cost_per_token": 1.5e-07,
          "output_cost_per_token": 6e-07,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "GPT-4 Turbo",
          "submodels": [
            "gpt-4-turbo",
            "gpt-4-turbo-2024-04-09"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 1e-05,
          "output_cost_per_token": 3e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "GPT-4 Turbo Preview",
          "submodels": [
            "gpt-4-turbo-preview",
            "gpt-4-1106-preview",
            "gpt-4-0125-preview"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 1e-05,
          "output_cost_per_token": 3e-05,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "GPT-4",
          "submodels": [
            "gpt-4",
            "gpt-4-0314",
            "gpt-4-0613"
          ],
          "max_input_tokens": 8192,
          "max_output_tokens": 4096,
          "input_cost_per_token": 3e-05,
          "output_cost_per_token": 6e-05,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "GPT-4 32k",
          "submodels": [
            "gpt-4-32k",
            "gpt-4-32k-0314",
            "gpt-4-32k-0613"
          ],
          "max_input_tokens": 32768,
          "max_output_tokens": 4096,
          "input_cost_per_token": 6e-05,
          "output_cost_per_token": 0.00012,
          "supports_function_calling": false,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "GPT-4 Vision",
          "submodels": [
            "gpt-4-vision-preview",
            "gpt-4-1106-vision-preview"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 1e-05,
          "output_cost_per_token": 3e-05,
          "supports_function_calling": false,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "GPT-3.5 Turbo",
          "submodels": [
            "gpt-3.5-turbo",
            "gpt-3.5-turbo-0301",
            "gpt-3.5-turbo-0613",
            "gpt-3.5-turbo-1106",
            "gpt-3.5-turbo-0125"
          ],
          "max_input_tokens": 4097,
          "max_output_tokens": 4096,
          "input_cost_per_token": 1.5e-06,
          "output_cost_per_token": 2e-06,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "GPT-3.5 Turbo 16k",
          "submodels": [
            "gpt-3.5-turbo-16k",
            "gpt-3.5-turbo-16k-0613"
          ],
          "max_input_tokens": 16385,
          "max_output_tokens": 4096,
          "input_cost_per_token": 3e-06,
          "output_cost_per_token": 4e-06,
          "supports_function_calling": false,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "o1",
          "submodels": [
            "o1",
            "o1-2024-12-17"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 100000,
          "input_cost_per_token": 1.5e-05,
          "output_cost_per_token": 6e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "o1-preview",
          "submodels": [
            "o1-preview",
            "o1-preview-2024-09-12"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 32768,
          "input_cost_per_token": 1.5e-05,
          "output_cost_per_token": 6e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "o1-mini",
          "submodels": [
            "o1-mini",
            "o1-mini-2024-09-12"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 65536,
          "input_cost_per_token": 1.1e-06,
          "output_cost_per_token": 4.4e-06,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "o3-mini",
          "submodels": [
            "o3-mini",
            "o3-mini-2025-01-31"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 100000,
          "input_cost_per_token": 1.1e-06,
          "output_cost_per_token": 4.4e-06,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "chatgpt-4o-latest",
          "submodels": [
            "chatgpt-4o-latest"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 5e-06,
          "output_cost_per_token": 1.5e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "GPT 4.1",
          "submodels": [
            "gpt-4.1",
            "gpt-4.1-2025-04-14"
          ],
          "max_input_tokens": 1047576,
          "max_output_tokens": 32768,
          "input_cost_per_token": 2e-06,
          "output_cost_per_token": 8e-06,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "GPT 4.1 Mini",
          "submodels": [
            "gpt-4.1-mini",
            "gpt-4.1-mini-2025-04-14"
          ],
          "max_input_tokens": 1047576,
          "max_output_tokens": 32768,
          "input_cost_per_token": 4e-07,
          "output_cost_per_token": 1.6e-06,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "GPT 4.1 Nano",
          "submodels": [
            "gpt-4.1-nano",
            "gpt-4.1-nano-2025-04-14"
          ],
          "max_input_tokens": 1047576,
          "max_output_tokens": 32768,
          "input_cost_per_token": 1e-07,
          "output_cost_per_token": 4e-07,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "GPT 5",
          "submodels": [
            "gpt-5",
            "gpt-5-2025-08-07"
          ],
          "max_input_tokens": 400000,
          "max_output_tokens": 128000,
          "input_cost_per_token": 1.25e-06,
          "output_cost_per_token": 1e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "GPT 5 Mini",
          "submodels": [
            "gpt-5-mini",
            "gpt-5-mini-2025-08-07"
          ],
          "max_input_tokens": 400000,
          "max_output_tokens": 128000,
          "input_cost_per_token": 2.5e-07,
          "output_cost_per_token": 2e-06,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "GPT 5 Nano",
          "submodels": [
            "gpt-5-nano",
            "gpt-5-nano-2025-08-07"
          ],
          "max_input_tokens": 400000,
          "max_output_tokens": 128000,
          "input_cost_per_token": 5e-08,
          "output_cost_per_token": 4e-07,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        }
      ]
    },
    {
      "name": "Bedrock",
      "displayName": "AWS Bedrock",
      "base_model_name": "bedrock",
      "credentials_needed": {
        "aws_region_name": {
          "type": "string",
          "displayName": "Nome da Regi√£o",
          "description": "Nome da Regi√£o da AWS. Por exemplo: us-east-1, sa-east-1, etc.",
          "required": true
        },
        "aws_access_key_id": {
          "type": "string",
          "displayName": "Access Key ID",
          "description": "AWS Access Key ID da conta com permiss√£o para usar o Bedrock. Garanta que deu as permiss√µes corretas no IAM.",
          "required": true
        },
        "aws_secret_access_key": {
          "type": "string",
          "displayName": "Secret Access Key",
          "description": "Secret Access Key da AWS ",
          "required": true
        }
      },
      "models": [
        {
          "displayName": "Jamba Instruct",
          "submodels": [
            "ai21.jamba-instruct-v1:0"
          ],
          "max_input_tokens": 70000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 5e-07,
          "output_cost_per_token": 7e-07,
          "supports_function_calling": false,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Jamba 1.5 Large",
          "submodels": [
            "ai21.jamba-1-5-large-v1:0"
          ],
          "max_input_tokens": 256000,
          "max_output_tokens": 256000,
          "input_cost_per_token": 2e-06,
          "output_cost_per_token": 8e-06,
          "supports_function_calling": false,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Jamba 1.5 Mini",
          "submodels": [
            "ai21.jamba-1-5-mini-v1:0"
          ],
          "max_input_tokens": 256000,
          "max_output_tokens": 256000,
          "input_cost_per_token": 2e-07,
          "output_cost_per_token": 4e-07,
          "supports_function_calling": false,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Titan Text Lite",
          "submodels": [
            "amazon.titan-text-lite-v1"
          ],
          "max_input_tokens": 42000,
          "max_output_tokens": 4000,
          "input_cost_per_token": 3e-07,
          "output_cost_per_token": 4e-07,
          "supports_function_calling": false,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Titan Text Express",
          "submodels": [
            "amazon.titan-text-express-v1"
          ],
          "max_input_tokens": 42000,
          "max_output_tokens": 8000,
          "input_cost_per_token": 1.3e-06,
          "output_cost_per_token": 1.7e-06,
          "supports_function_calling": false,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Titan Text Premier",
          "submodels": [
            "amazon.titan-text-premier-v1:0"
          ],
          "max_input_tokens": 42000,
          "max_output_tokens": 32000,
          "input_cost_per_token": 5e-07,
          "output_cost_per_token": 1.5e-06,
          "supports_function_calling": false,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Mistral 7B Instruct",
          "submodels": [
            "mistral.mistral-7b-instruct-v0:2"
          ],
          "max_input_tokens": 32000,
          "max_output_tokens": 8191,
          "input_cost_per_token": 1.5e-07,
          "output_cost_per_token": 2e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Mixtral 8x7B Instruct",
          "submodels": [
            "mistral.mixtral-8x7b-instruct-v0:1"
          ],
          "max_input_tokens": 32000,
          "max_output_tokens": 8191,
          "input_cost_per_token": 4.5e-07,
          "output_cost_per_token": 7e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Mistral Large",
          "submodels": [
            "mistral.mistral-large-2402-v1:0"
          ],
          "max_input_tokens": 32000,
          "max_output_tokens": 8191,
          "input_cost_per_token": 8e-06,
          "output_cost_per_token": 2.4e-05,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Mistral Small",
          "submodels": [
            "mistral.mistral-small-2402-v1:0"
          ],
          "max_input_tokens": 32000,
          "max_output_tokens": 8191,
          "input_cost_per_token": 1e-06,
          "output_cost_per_token": 3e-06,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Claude 3 Sonnet",
          "submodels": [
            "us.anthropic.claude-3-sonnet-20240229-v1:0"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 3e-06,
          "output_cost_per_token": 1.5e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Claude 3.5 Sonnet",
          "submodels": [
            "us.anthropic.claude-3-5-sonnet-20240620-v1:0",
            "us.anthropic.claude-3-5-sonnet-20241022-v2:0"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 3e-06,
          "output_cost_per_token": 1.5e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Claude 3 Haiku",
          "submodels": [
            "us.anthropic.claude-3-haiku-20240307-v1:0"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 2.5e-07,
          "output_cost_per_token": 1.25e-06,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Claude 3.5 Haiku",
          "submodels": [
            "us.anthropic.claude-3-5-haiku-20241022-v1:0"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 8192,
          "input_cost_per_token": 8e-07,
          "output_cost_per_token": 4e-06,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Claude 3 Opus",
          "submodels": [
            "us.anthropic.claude-3-opus-20240229-v1:0"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 1.5e-05,
          "output_cost_per_token": 7.5e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Claude 3.7 Sonnet",
          "submodels": [
            "us.anthropic.claude-3-7-sonnet-20250219-v1:0"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 8192,
          "input_cost_per_token": 3e-06,
          "output_cost_per_token": 1.5e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Command Text",
          "submodels": [
            "cohere.command-text-v14"
          ],
          "max_input_tokens": 4096,
          "max_output_tokens": 4096,
          "input_cost_per_token": 1.5e-06,
          "output_cost_per_token": 2e-06,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Command Light Text",
          "submodels": [
            "cohere.command-light-text-v14"
          ],
          "max_input_tokens": 4096,
          "max_output_tokens": 4096,
          "input_cost_per_token": 3e-07,
          "output_cost_per_token": 6e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Command R+",
          "submodels": [
            "cohere.command-r-plus-v1:0"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 3e-06,
          "output_cost_per_token": 1.5e-05,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Command R",
          "submodels": [
            "cohere.command-r-v1:0"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 5e-07,
          "output_cost_per_token": 1.5e-06,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Llama3 8B Instruct",
          "submodels": [
            "meta.llama3-8b-instruct-v1:0"
          ],
          "max_input_tokens": 8192,
          "max_output_tokens": 8192,
          "input_cost_per_token": 3e-07,
          "output_cost_per_token": 6e-07,
          "supports_function_calling": false,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Llama3 70B Instruct",
          "submodels": [
            "meta.llama3-70b-instruct-v1:0"
          ],
          "max_input_tokens": 8192,
          "max_output_tokens": 8192,
          "input_cost_per_token": 2.65e-06,
          "output_cost_per_token": 3.5e-06,
          "supports_function_calling": false,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Llama3 1-8B Instruct",
          "submodels": [
            "us.meta.llama3-1-8b-instruct-v1:0"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 2048,
          "input_cost_per_token": 2.2e-07,
          "output_cost_per_token": 2.2e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Llama3 1-70B Instruct",
          "submodels": [
            "us.meta.llama3-1-70b-instruct-v1:0"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 2048,
          "input_cost_per_token": 9.9e-07,
          "output_cost_per_token": 9.9e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Llama3 2-1B Instruct",
          "submodels": [
            "us.meta.llama3-2-1b-instruct-v1:0"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 1e-07,
          "output_cost_per_token": 1e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Llama3 2-3B Instruct",
          "submodels": [
            "us.meta.llama3-2-3b-instruct-v1:0"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 1.5e-07,
          "output_cost_per_token": 1.5e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Llama3 2-11B Instruct",
          "submodels": [
            "us.meta.llama3-2-11b-instruct-v1:0"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 3.5e-07,
          "output_cost_per_token": 3.5e-07,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Llama3 2-90B Instruct",
          "submodels": [
            "us.meta.llama3-2-90b-instruct-v1:0"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 2e-06,
          "output_cost_per_token": 2e-06,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        }
      ]
    },
    {
      "name": "Azure AI",
      "displayName": "Azure",
      "base_model_name": "azure_ai",
      "credentials_needed": {
        "api_key": {
          "type": "string",
          "displayName": "Chave de API",
          "description": "Chave de API da Azure AI",
          "required": true
        },
        "base_url": {
          "type": "string",
          "displayName": "URL Base",
          "description": "Base URL da Azure AI",
          "required": true
        }
      },
      "models": [
        {
          "displayName": "Deepseek",
          "submodels": [
            "deepseek-r1",
            "DeepSeek-V3.1"            
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 8192,
          "input_cost_per_token": 1.35e-06,
          "output_cost_per_token": 5.4e-06,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Deepseek V3",
          "submodels": [
            "deepseek-v3"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 8192,
          "input_cost_per_token": 1.35e-06,
          "output_cost_per_token": 5.4e-06,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "deprecated"
        },
        {
          "displayName": "Jamba Instruct",
          "submodels": [
            "jamba-instruct"
          ],
          "max_input_tokens": 70000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 5e-07,
          "output_cost_per_token": 7e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "deprecated"
        },
        {
          "displayName": "Mistral Nemo",
          "submodels": [
            "mistral-nemo"
          ],
          "max_input_tokens": 131072,
          "max_output_tokens": 4096,
          "input_cost_per_token": 1.5e-07,
          "output_cost_per_token": 1.5e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "deprecated"
        },
        {
          "displayName": "Mistral Large",
          "submodels": [
            "mistral-large",
            "mistral-large-2407"
          ],
          "max_input_tokens": 32000,
          "max_output_tokens": 8191,
          "input_cost_per_token": 4e-06,
          "output_cost_per_token": 1.2e-05,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "deprecated"
        },
        {
          "displayName": "Mistral Small",
          "submodels": [
            "mistral-small",
            "mistral-small-2503"
          ],
          "max_input_tokens": 32000,
          "max_output_tokens": 8191,
          "input_cost_per_token": 1e-06,
          "output_cost_per_token": 3e-06,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "deprecated"
        },
        {
          "displayName": "Llama-3.2 11B Vision Instruct",
          "submodels": [
            "Llama-3.2-11B-Vision-Instruct"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 2048,
          "input_cost_per_token": 3.7e-07,
          "output_cost_per_token": 3.7e-07,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "deprecated"
        },
        {
          "displayName": "Llama-3.3 70B Instruct",
          "submodels": [
            "Llama-3.3-70B-Instruct"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 2048,
          "input_cost_per_token": 7.1e-07,
          "output_cost_per_token": 7.1e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Meta-Llama-3 70B Instruct",
          "submodels": [
            "Meta-Llama-3-70B-Instruct"
          ],
          "max_input_tokens": 8192,
          "max_output_tokens": 2048,
          "input_cost_per_token": 1.1e-06,
          "output_cost_per_token": 3.7e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "deprecated"
        },
        {
          "displayName": "Meta-Llama-3.1 8B Instruct",
          "submodels": [
            "Meta-Llama-3.1-8B-Instruct"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 2048,
          "input_cost_per_token": 3e-07,
          "output_cost_per_token": 6.1e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "deprecated"
        },
        {
          "displayName": "Meta-Llama-3.1 70B Instruct",
          "submodels": [
            "Meta-Llama-3.1-70B-Instruct"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 2048,
          "input_cost_per_token": 2.68e-06,
          "output_cost_per_token": 3.54e-06,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "deprecated"
        },
        {
          "displayName": "Meta-Llama-3.1 405B Instruct",
          "submodels": [
            "Meta-Llama-3.1-405B-Instruct"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 2048,
          "input_cost_per_token": 5.33e-06,
          "output_cost_per_token": 1.6e-05,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "deprecated"
        },
        {
          "displayName": "Phi-4-mini-instruct",
          "submodels": [
            "Phi-4-mini-instruct"
          ],
          "max_input_tokens": 131072,
          "max_output_tokens": 4096,
          "input_cost_per_token": 0,
          "output_cost_per_token": 0,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Phi-4-multimodal-instruct",
          "submodels": [
            "Phi-4-multimodal-instruct"
          ],
          "max_input_tokens": 131072,
          "max_output_tokens": 4096,
          "input_cost_per_token": 0,
          "output_cost_per_token": 0,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Phi-4",
          "submodels": [
            "Phi-4"
          ],
          "max_input_tokens": 16384,
          "max_output_tokens": 16384,
          "input_cost_per_token": 1.25e-07,
          "output_cost_per_token": 5e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Phi-3.5-mini-instruct",
          "submodels": [
            "Phi-3.5-mini-instruct"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 1.3e-07,
          "output_cost_per_token": 5.2e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "deprecated"
        },
        {
          "displayName": "Phi-3.5-vision-instruct",
          "submodels": [
            "Phi-3.5-vision-instruct"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 1.3e-07,
          "output_cost_per_token": 5.2e-07,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "deprecated"
        },
        {
          "displayName": "Phi-3.5-MoE-instruct",
          "submodels": [
            "Phi-3.5-MoE-instruct"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 1.6e-07,
          "output_cost_per_token": 6.4e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "deprecated"
        },
        {
          "displayName": "Phi-3-mini-4k-instruct",
          "submodels": [
            "Phi-3-mini-4k-instruct"
          ],
          "max_input_tokens": 4096,
          "max_output_tokens": 4096,
          "input_cost_per_token": 1.3e-07,
          "output_cost_per_token": 5.2e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "deprecated"
        },
        {
          "displayName": "Phi-3-mini-128k-instruct",
          "submodels": [
            "Phi-3-mini-128k-instruct"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 1.3e-07,
          "output_cost_per_token": 5.2e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "deprecated"
        },
        {
          "displayName": "Phi-3-small-8k-instruct",
          "submodels": [
            "Phi-3-small-8k-instruct"
          ],
          "max_input_tokens": 8192,
          "max_output_tokens": 4096,
          "input_cost_per_token": 1.5e-07,
          "output_cost_per_token": 6e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "deprecated"
        },
        {
          "displayName": "Phi-3-small-128k-instruct",
          "submodels": [
            "Phi-3-small-128k-instruct"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 1.5e-07,
          "output_cost_per_token": 6e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "deprecated"
        },
        {
          "displayName": "GPT-4o",
          "submodels": [
            "gpt-4o"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 16384,
          "input_cost_per_token": 2.5e-06,
          "output_cost_per_token": 1e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "GPT-4o mini",
          "submodels": [
            "gpt-4o-mini"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 16384,
          "input_cost_per_token": 1.5e-07,
          "output_cost_per_token": 6e-07,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        }
      ]
    },
    {
      "name": "Google AI",
      "displayName": "Google AI",
      "base_model_name": "gemini",
      "credentials_needed": {
        "api_key": {
          "type": "string",
          "displayName": "Chave de API",
          "description": "Chaven de API do Est√∫dio de IA da Google",
          "required": true
        }
      },
      "models": [
        {
          "displayName": "Gemini 2.0 Flash",
          "submodels": [
            "gemini-2.0-flash",
            "gemini-2.0-flash-001"
          ],
          "max_input_tokens": 1048576,
          "max_output_tokens": 8192,
          "input_cost_per_token": 1e-07,
          "output_cost_per_token": 4e-07,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Gemini 2.0 Flash Lite",
          "submodels": [
            "gemini-2.0-flash-lite",
            "gemini-2.0-flash-lite-preview-02-05"
          ],
          "max_input_tokens": 1048576,
          "max_output_tokens": 8192,
          "input_cost_per_token": 7.5e-08,
          "output_cost_per_token": 3e-07,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Gemini 2.0 Flash Exp",
          "submodels": [
            "gemini-2.0-flash-exp"
          ],
          "max_input_tokens": 1048576,
          "max_output_tokens": 8192,
          "input_cost_per_token": 0,
          "output_cost_per_token": 0,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Gemini 2.0 Flash Thinking Exp",
          "submodels": [
            "gemini-2.0-flash-thinking-exp",
            "gemini-2.0-flash-thinking-exp-01-21"
          ],
          "max_input_tokens": 1048576,
          "max_output_tokens": 65536,
          "input_cost_per_token": 0,
          "output_cost_per_token": 0,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Gemini 1.5 Flash",
          "submodels": [
            "gemini-1.5-flash",
            "gemini-1.5-flash-002",
            "gemini-1.5-flash-001",
            "gemini-1.5-flash-latest"
          ],
          "max_input_tokens": 1048576,
          "max_output_tokens": 8192,
          "input_cost_per_token": 7.5e-08,
          "output_cost_per_token": 3e-07,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Gemini 1.5 Flash 8B",
          "submodels": [
            "gemini-1.5-flash-8b",
            "gemini-1.5-flash-8b-exp-0924",
            "gemini-1.5-flash-8b-exp-0827"
          ],
          "max_input_tokens": 1048576,
          "max_output_tokens": 8192,
          "input_cost_per_token": 0,
          "output_cost_per_token": 0,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Gemini 1.5 Pro",
          "submodels": [
            "gemini-1.5-pro",
            "gemini-1.5-pro-002",
            "gemini-1.5-pro-001",
            "gemini-1.5-pro-exp-0801",
            "gemini-1.5-pro-exp-0827",
            "gemini-1.5-pro-latest"
          ],
          "max_input_tokens": 2097152,
          "max_output_tokens": 8192,
          "input_cost_per_token": 3.5e-06,
          "output_cost_per_token": 1.05e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Gemini Pro Vision",
          "submodels": [
            "gemini-pro-vision"
          ],
          "max_input_tokens": 30720,
          "max_output_tokens": 2048,
          "input_cost_per_token": 3.5e-07,
          "output_cost_per_token": 1.05e-06,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Gemini Gemma 2",
          "submodels": [
            "gemini-gemma-2-27b-it"
          ],
          "max_input_tokens": null,
          "max_output_tokens": 8192,
          "input_cost_per_token": 3.5e-07,
          "output_cost_per_token": 1.05e-06,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Gemini Gemma 2 (9B)",
          "submodels": [
            "gemini-gemma-2-9b-it"
          ],
          "max_input_tokens": null,
          "max_output_tokens": 8192,
          "input_cost_per_token": 3.5e-07,
          "output_cost_per_token": 1.05e-06,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Gemini 2.5 Pro",
          "submodels": [
            "gemini-2.5-pro-preview-05-06",
            "gemini-2.5-pro-preview-03-25"
          ],
          "max_input_tokens": 1048576,
          "max_output_tokens": 65535,
          "input_cost_per_token": 1.25e-06,
          "output_cost_per_token": 1e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Gemini 2.5 Flash",
          "submodels": [
            "gemini-2.5-flash-preview-05-20",
            "gemini-2.5-flash-preview-04-17"
          ],
          "max_input_tokens": 1048576,
          "max_output_tokens": 65535,
          "input_cost_per_token": 1.5e-07,
          "output_cost_per_token": 6e-07,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        }
      ]
    },
    {
      "name": "Fireworks AI",
      "displayName": "AumoGPT",
      "base_model_name": "fireworks_ai",
      "credentials_needed": {
        "api_key": {
          "type": "string",
          "displayName": "Chave de API",
          "description": "Chave de API do AumoGPT. Entrar em contato com o suporte da AUMO para obter uma chave de API.",
          "required": true
        }
      },
      "models": [
        {
          "displayName": "Llama-3.1 8B",
          "submodels": [
            "llama-v3p1-8b-instruct"
          ],
          "max_input_tokens": 16384,
          "max_output_tokens": 16384,
          "input_cost_per_token": 1e-07,
          "output_cost_per_token": 1e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Deepseek v3",
          "submodels": [
            "deepseek-v3"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 8192,
          "input_cost_per_token": 9e-07,
          "output_cost_per_token": 9e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "GPT OSS 20B",
          "submodels": [
            "gpt-oss-20b"
          ],
          "max_input_tokens": 131072,
          "max_output_tokens": 131072,
          "input_cost_per_token": 5e-08,
          "output_cost_per_token": 2e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "GPT OSS 120b",
          "submodels": [
            "gpt-oss-120b"
          ],
          "max_input_tokens": 131072,
          "max_output_tokens": 131072,
          "input_cost_per_token": 1.5e-07,
          "output_cost_per_token": 6e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "AumoGPT 7b",
          "submodels": [
            "accounts/admin-d353ad/deployedModels/aumogpt-7b-v1-hniaz8ub"
          ],
          "max_input_tokens": 30720,
          "max_output_tokens": 16384,
          "input_cost_per_token": 1e-07,
          "output_cost_per_token": 1e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "AumoGPT 70b",
          "submodels": [
            "accounts/admin-d353ad/deployedModels/aumogpt-70b-v1-cezpimyl"
          ],
          "max_input_tokens": 30720,
          "max_output_tokens": 16384,
          "input_cost_per_token": 1e-07,
          "output_cost_per_token": 1e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        }
      ]
    },
    {
      "name": "OCI",
      "displayName": "Oracle OCI",
      "base_model_name": "oci",
      "credentials_needed": {
        "key": {
          "type": "string",
          "displayName": "Chave Privada",
          "description": "Private Key da Oracle",
          "required": true
        },
        "user": {
          "type": "string",
          "displayName": "Usu√°rio",
          "description": "ID do Usu√°rio da Oracle",
          "required": true
        },
        "region": {
          "type": "string",
          "displayName": "Regi√£o",
          "description": "Nome da Regi√£o da Oracle",
          "required": true
        },
        "tenancy": {
          "type": "string",
          "displayName": "Tenancy",
          "description": "O ID do Tenant da Oracle",
          "required": true
        },
        "fingerprint": {
          "type": "string",
          "displayName": "Fingerprint",
          "description": "Oracle Fingerprint",
          "required": true
        },
        "compartment_id": {
          "type": "string",
          "displayName": "Compartment ID",
          "description": "Oracle Compartment ID",
          "required": true
        }
      },
      "models": [
        {
          "displayName": "Grok 4",
          "submodels": [
            "xai.grok-4"
          ],
          "max_tokens": 128000,
          "max_input_tokens": 128000,
          "max_output_tokens": 128000,
          "input_cost_per_token": 3e-06,
          "output_cost_per_token": 1.5e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Grok 3",
          "submodels": [
            "xai.grok-3"
          ],
          "max_input_tokens": 131072,
          "max_output_tokens": 131072,
          "input_cost_per_token": 3e-06,
          "output_cost_per_token": 1.5e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Grok 3 Fast",
          "submodels": [
            "xai.grok-3-fast"
          ],
          "max_input_tokens": 131072,
          "max_output_tokens": 131072,
          "input_cost_per_token": 5e-06,
          "output_cost_per_token": 2.5e-05,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Grok 3 Mini",
          "submodels": [
            "xai.grok-3-mini"
          ],
          "max_input_tokens": 131072,
          "max_output_tokens": 131072,
          "input_cost_per_token": 3e-07,
          "output_cost_per_token": 5e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Grok 3 Mini Fast",
          "submodels": [
            "xai.grok-3-mini-fast"
          ],
          "max_input_tokens": 131072,
          "max_output_tokens": 131072,
          "input_cost_per_token": 6e-07,
          "output_cost_per_token": 4e-06,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        }
      ]
    }
  ]
}
