{
  "providers": [
    {
      "name": "Mock",
      "displayName": "Mock",
      "base_model_name": "mock",
      "credentials_needed": {},
      "models": [
        {
          "displayName": "Mock Model",
          "submodels": [
            "mock"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 16384,
          "input_cost_per_token": 2.5e-06,
          "output_cost_per_token": 1e-05,
          "supports_function_calling": false,
          "supports_vision": true,
          "status": "active"
        }
      ]
    },
    {
      "name": "OpenAI",
      "displayName": "OpenAI",
      "base_model_name": "openai",
      "credentials_needed": {
        "api_key": {
          "type": "string",
          "displayName": "Chave de API",
          "description": "Chave de API da OpenAI",
          "required": true
        }
      },
      "models": [
        {
          "displayName": "GPT-4o",
          "submodels": [
            "gpt-4o",
            "gpt-4o-2024-08-06",
            "gpt-4o-2024-05-13",
            "gpt-4o-2024-11-20"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 16384,
          "input_cost_per_token": 2.5e-06,
          "output_cost_per_token": 1e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "GPT-4o mini",
          "submodels": [
            "gpt-4o-mini",
            "gpt-4o-mini-2024-07-18"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 16384,
          "input_cost_per_token": 1.5e-07,
          "output_cost_per_token": 6e-07,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "GPT-4 Turbo",
          "submodels": [
            "gpt-4-turbo",
            "gpt-4-turbo-2024-04-09"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 1e-05,
          "output_cost_per_token": 3e-05,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "GPT-4 Turbo Preview",
          "submodels": [
            "gpt-4-turbo-preview",
            "gpt-4-1106-preview",
            "gpt-4-0125-preview"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 1e-05,
          "output_cost_per_token": 3e-05,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "GPT-4",
          "submodels": [
            "gpt-4",
            "gpt-4-0613"
          ],
          "max_input_tokens": 8192,
          "max_output_tokens": 4096,
          "input_cost_per_token": 3e-05,
          "output_cost_per_token": 6e-05,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "GPT-3.5 Turbo",
          "submodels": [
            "gpt-3.5-turbo",
            "gpt-3.5-turbo-1106",
            "gpt-3.5-turbo-0125"
          ],
          "max_input_tokens": 4097,
          "max_output_tokens": 4096,
          "input_cost_per_token": 1.5e-06,
          "output_cost_per_token": 2e-06,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "GPT-3.5 Turbo 16k",
          "submodels": [
            "gpt-3.5-turbo-16k"
          ],
          "max_input_tokens": 16385,
          "max_output_tokens": 4096,
          "input_cost_per_token": 3e-06,
          "output_cost_per_token": 4e-06,
          "supports_function_calling": false,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "o1",
          "submodels": [
            "o1",
            "o1-2024-12-17"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 100000,
          "input_cost_per_token": 1.5e-05,
          "output_cost_per_token": 6e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "o3-mini",
          "submodels": [
            "o3-mini",
            "o3-mini-2025-01-31"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 100000,
          "input_cost_per_token": 1.1e-06,
          "output_cost_per_token": 4.4e-06,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "chatgpt-4o-latest",
          "submodels": [
            "chatgpt-4o-latest"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 5e-06,
          "output_cost_per_token": 1.5e-05,
          "supports_function_calling": false,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "GPT 4.1",
          "submodels": [
            "gpt-4.1",
            "gpt-4.1-2025-04-14"
          ],
          "max_input_tokens": 1047576,
          "max_output_tokens": 32768,
          "input_cost_per_token": 2e-06,
          "output_cost_per_token": 8e-06,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "GPT 4.1 Mini",
          "submodels": [
            "gpt-4.1-mini",
            "gpt-4.1-mini-2025-04-14"
          ],
          "max_input_tokens": 1047576,
          "max_output_tokens": 32768,
          "input_cost_per_token": 4e-07,
          "output_cost_per_token": 1.6e-06,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "GPT 4.1 Nano",
          "submodels": [
            "gpt-4.1-nano",
            "gpt-4.1-nano-2025-04-14"
          ],
          "max_input_tokens": 1047576,
          "max_output_tokens": 32768,
          "input_cost_per_token": 1e-07,
          "output_cost_per_token": 4e-07,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "GPT 5",
          "submodels": [
            "gpt-5",
            "gpt-5-2025-08-07"
          ],
          "max_input_tokens": 400000,
          "max_output_tokens": 128000,
          "input_cost_per_token": 1.25e-06,
          "output_cost_per_token": 1e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "GPT 5 Mini",
          "submodels": [
            "gpt-5-mini",
            "gpt-5-mini-2025-08-07"
          ],
          "max_input_tokens": 400000,
          "max_output_tokens": 128000,
          "input_cost_per_token": 2.5e-07,
          "output_cost_per_token": 2e-06,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "GPT 5 Nano",
          "submodels": [
            "gpt-5-nano",
            "gpt-5-nano-2025-08-07"
          ],
          "max_input_tokens": 400000,
          "max_output_tokens": 128000,
          "input_cost_per_token": 5e-08,
          "output_cost_per_token": 4e-07,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "GPT 5.2",
          "submodels": [
            "gpt-5.2",
            "gpt-5.2-2025-12-11"
          ],
          "max_input_tokens": 400000,
          "max_output_tokens": 128000,
          "input_cost_per_token": 1.75e-06,
          "output_cost_per_token": 1.4e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        }
      ]
    },
    {
      "name": "Bedrock",
      "displayName": "AWS Bedrock",
      "base_model_name": "bedrock",
      "credentials_needed": {
        "aws_region_name": {
          "type": "string",
          "displayName": "Nome da Região",
          "description": "Nome da Região da AWS. Por exemplo: us-east-1, sa-east-1, etc.",
          "required": true
        },
        "aws_access_key_id": {
          "type": "string",
          "displayName": "Access Key ID",
          "description": "AWS Access Key ID da conta com permissão para usar o Bedrock. Garanta que deu as permissões corretas no IAM.",
          "required": true
        },
        "aws_secret_access_key": {
          "type": "string",
          "displayName": "Secret Access Key",
          "description": "Secret Access Key da AWS ",
          "required": true
        }
      },
      "models": [
        {
          "displayName": "Mistral 7B Instruct",
          "submodels": [
            "mistral.mistral-7b-instruct-v0:2"
          ],
          "max_input_tokens": 32000,
          "max_output_tokens": 8191,
          "input_cost_per_token": 1.5e-07,
          "output_cost_per_token": 2e-07,
          "supports_function_calling": false,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Mixtral 8x7B Instruct",
          "submodels": [
            "mistral.mixtral-8x7b-instruct-v0:1"
          ],
          "max_input_tokens": 32000,
          "max_output_tokens": 8191,
          "input_cost_per_token": 4.5e-07,
          "output_cost_per_token": 7e-07,
          "supports_function_calling": false,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Mistral Large",
          "submodels": [
            "mistral.mistral-large-2402-v1:0"
          ],
          "max_input_tokens": 32000,
          "max_output_tokens": 8191,
          "input_cost_per_token": 8e-06,
          "output_cost_per_token": 2.4e-05,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Mistral Small",
          "submodels": [
            "mistral.mistral-small-2402-v1:0"
          ],
          "max_input_tokens": 32000,
          "max_output_tokens": 8191,
          "input_cost_per_token": 1e-06,
          "output_cost_per_token": 3e-06,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Claude 3 Sonnet",
          "submodels": [
            "us.anthropic.claude-3-sonnet-20240229-v1:0"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 3e-06,
          "output_cost_per_token": 1.5e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Claude 3.5 Sonnet",
          "submodels": [
            "us.anthropic.claude-3-5-sonnet-20240620-v1:0",
            "us.anthropic.claude-3-5-sonnet-20241022-v2:0"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 3e-06,
          "output_cost_per_token": 1.5e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Claude 3 Haiku",
          "submodels": [
            "us.anthropic.claude-3-haiku-20240307-v1:0"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 2.5e-07,
          "output_cost_per_token": 1.25e-06,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Claude 3.5 Haiku",
          "submodels": [
            "us.anthropic.claude-3-5-haiku-20241022-v1:0"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 8192,
          "input_cost_per_token": 8e-07,
          "output_cost_per_token": 4e-06,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Claude 3 Opus",
          "submodels": [
            "us.anthropic.claude-3-opus-20240229-v1:0"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 1.5e-05,
          "output_cost_per_token": 7.5e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Claude 3.7 Sonnet",
          "submodels": [
            "us.anthropic.claude-3-7-sonnet-20250219-v1:0"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 8192,
          "input_cost_per_token": 3e-06,
          "output_cost_per_token": 1.5e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Claude Opus 4.5",
          "submodels": [
            "global.anthropic.claude-opus-4-5-20251101-v1:0"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 16384,
          "input_cost_per_token": 5e-06,
          "output_cost_per_token": 2.5e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Claude Haiku 4.5",
          "submodels": [
            "global.anthropic.claude-haiku-4-5-20251001-v1:0"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 8192,
          "input_cost_per_token": 1e-06,
          "output_cost_per_token": 5e-06,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Claude Sonnet 4.5",
          "submodels": [
            "global.anthropic.claude-sonnet-4-5-20250929-v1:0"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 16384,
          "input_cost_per_token": 3e-06,
          "output_cost_per_token": 1.5e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Claude Sonnet 4",
          "submodels": [
            "global.anthropic.claude-sonnet-4-20250514-v1:0"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 16384,
          "input_cost_per_token": 3e-06,
          "output_cost_per_token": 1.5e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Claude Opus 4.6",
          "submodels": [
            "us.anthropic.claude-opus-4-6-v1"
          ],
          "max_input_tokens": 1000000,
          "max_output_tokens": 128000,
          "input_cost_per_token": 5e-06,
          "output_cost_per_token": 2.5e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Llama3 8B Instruct",
          "submodels": [
            "meta.llama3-8b-instruct-v1:0"
          ],
          "max_input_tokens": 8192,
          "max_output_tokens": 8192,
          "input_cost_per_token": 3e-07,
          "output_cost_per_token": 6e-07,
          "supports_function_calling": false,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Llama3 70B Instruct",
          "submodels": [
            "meta.llama3-70b-instruct-v1:0"
          ],
          "max_input_tokens": 8192,
          "max_output_tokens": 8192,
          "input_cost_per_token": 2.65e-06,
          "output_cost_per_token": 3.5e-06,
          "supports_function_calling": false,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Llama3 1-8B Instruct",
          "submodels": [
            "us.meta.llama3-1-8b-instruct-v1:0"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 2048,
          "input_cost_per_token": 2.2e-07,
          "output_cost_per_token": 2.2e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Llama3 1-70B Instruct",
          "submodels": [
            "us.meta.llama3-1-70b-instruct-v1:0"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 2048,
          "input_cost_per_token": 9.9e-07,
          "output_cost_per_token": 9.9e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Llama3 2-1B Instruct",
          "submodels": [
            "us.meta.llama3-2-1b-instruct-v1:0"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 1e-07,
          "output_cost_per_token": 1e-07,
          "supports_function_calling": false,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Llama3 2-3B Instruct",
          "submodels": [
            "us.meta.llama3-2-3b-instruct-v1:0"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 1.5e-07,
          "output_cost_per_token": 1.5e-07,
          "supports_function_calling": false,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Llama3 2-11B Instruct",
          "submodels": [
            "us.meta.llama3-2-11b-instruct-v1:0"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 3.5e-07,
          "output_cost_per_token": 3.5e-07,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Llama3 2-90B Instruct",
          "submodels": [
            "us.meta.llama3-2-90b-instruct-v1:0"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 2e-06,
          "output_cost_per_token": 2e-06,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "OpenAI GPT OSS 120B",
          "submodels": [
            "openai.gpt-oss-120b-1:0"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 8191,
          "input_cost_per_token": 1e-06,
          "output_cost_per_token": 3e-06,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "OpenAI GPT OSS 20B",
          "submodels": [
            "openai.gpt-oss-20b-1:0"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 8191,
          "input_cost_per_token": 1e-06,
          "output_cost_per_token": 3e-06,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Qwen3 32B",
          "submodels": [
            "qwen.qwen3-32b-v1:0"
          ],
          "max_input_tokens": 16384,
          "max_output_tokens": 8191,
          "input_cost_per_token": 1.5e-07,
          "output_cost_per_token": 6e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Qwen3 Coder 30B",
          "submodels": [
            "qwen.qwen3-coder-30b-a3b-v1:0"
          ],
          "max_input_tokens": 262144,
          "max_output_tokens": 8191,
          "input_cost_per_token": 1.5e-07,
          "output_cost_per_token": 6e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Qwen3 Next 80B A3B",
          "submodels": [
            "qwen.qwen3-next-80b-a3b"
          ],
          "max_input_tokens": 262144,
          "max_output_tokens": 8191,
          "input_cost_per_token": 1.5e-07,
          "output_cost_per_token": 1.2e-06,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Ministral 14B 3.0",
          "submodels": [
            "mistral.ministral-3-14b-instruct"
          ],
          "max_input_tokens": 262144,
          "max_output_tokens": 8191,
          "input_cost_per_token": 2e-07,
          "output_cost_per_token": 2e-07,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "NVIDIA Nemotron Nano 2",
          "submodels": [
            "nvidia.nemotron-nano-9b-v2"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 8191,
          "input_cost_per_token": 6e-08,
          "output_cost_per_token": 2.3e-07,
          "supports_function_calling": false,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "NVIDIA Nemotron Nano 2 VL",
          "submodels": [
            "nvidia.nemotron-nano-12b-v2"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 8191,
          "input_cost_per_token": 2e-07,
          "output_cost_per_token": 6e-07,
          "supports_function_calling": false,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Nemotron Nano 3 30B",
          "submodels": [
            "nvidia.nemotron-nano-3-30b"
          ],
          "max_input_tokens": 262144,
          "max_output_tokens": 8191,
          "input_cost_per_token": 1.5e-07,
          "output_cost_per_token": 6e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        }
      ]
    },
    {
      "name": "Azure AI",
      "displayName": "Azure",
      "base_model_name": "azure_ai",
      "credentials_needed": {
        "api_key": {
          "type": "string",
          "displayName": "Chave de API",
          "description": "Chave de API da Azure AI",
          "required": true
        },
        "base_url": {
          "type": "string",
          "displayName": "URL Base",
          "description": "Base URL da Azure AI",
          "required": true
        }
      },
      "models": [
        {
          "displayName": "Deepseek R1",
          "submodels": [
            "deepseek-r1"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 8192,
          "input_cost_per_token": 1.35e-06,
          "output_cost_per_token": 5.4e-06,
          "supports_function_calling": false,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Deepseek V3.1",
          "submodels": [
            "DeepSeek-V3.1"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 8192,
          "input_cost_per_token": 1.35e-06,
          "output_cost_per_token": 5.4e-06,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Mistral Nemo",
          "submodels": [
            "mistral-nemo"
          ],
          "max_input_tokens": 131072,
          "max_output_tokens": 4096,
          "input_cost_per_token": 1.5e-07,
          "output_cost_per_token": 1.5e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "deprecated"
        },
        {
          "displayName": "Mistral Small",
          "submodels": [
            "mistral-small-2503"
          ],
          "max_input_tokens": 32000,
          "max_output_tokens": 8191,
          "input_cost_per_token": 1e-06,
          "output_cost_per_token": 3e-06,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "deprecated"
        },
        {
          "displayName": "Llama-3.2 11B Vision Instruct",
          "submodels": [
            "Llama-3.2-11B-Vision-Instruct"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 2048,
          "input_cost_per_token": 3.7e-07,
          "output_cost_per_token": 3.7e-07,
          "supports_function_calling": false,
          "supports_vision": true,
          "status": "deprecated"
        },
        {
          "displayName": "Llama-3.3 70B Instruct",
          "submodels": [
            "Llama-3.3-70B-Instruct"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 2048,
          "input_cost_per_token": 7.1e-07,
          "output_cost_per_token": 7.1e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Meta-Llama-3.1 8B Instruct",
          "submodels": [
            "Meta-Llama-3.1-8B-Instruct"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 2048,
          "input_cost_per_token": 3e-07,
          "output_cost_per_token": 6.1e-07,
          "supports_function_calling": false,
          "supports_vision": false,
          "status": "deprecated"
        },
        {
          "displayName": "Meta-Llama-3.1 405B Instruct",
          "submodels": [
            "Meta-Llama-3.1-405B-Instruct"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 2048,
          "input_cost_per_token": 5.33e-06,
          "output_cost_per_token": 1.6e-05,
          "supports_function_calling": false,
          "supports_vision": false,
          "status": "deprecated"
        },
        {
          "displayName": "Phi-4-mini-instruct",
          "submodels": [
            "Phi-4-mini-instruct"
          ],
          "max_input_tokens": 131072,
          "max_output_tokens": 4096,
          "input_cost_per_token": 0,
          "output_cost_per_token": 0,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Phi-4-multimodal-instruct",
          "submodels": [
            "Phi-4-multimodal-instruct"
          ],
          "max_input_tokens": 131072,
          "max_output_tokens": 4096,
          "input_cost_per_token": 0,
          "output_cost_per_token": 0,
          "supports_function_calling": false,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Phi-4",
          "submodels": [
            "Phi-4"
          ],
          "max_input_tokens": 16384,
          "max_output_tokens": 16384,
          "input_cost_per_token": 1.25e-07,
          "output_cost_per_token": 5e-07,
          "supports_function_calling": false,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "GPT-4o",
          "submodels": [
            "gpt-4o"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 16384,
          "input_cost_per_token": 2.5e-06,
          "output_cost_per_token": 1e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "GPT-4o mini",
          "submodels": [
            "gpt-4o-mini"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 16384,
          "input_cost_per_token": 1.5e-07,
          "output_cost_per_token": 6e-07,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "GPT 5",
          "submodels": [
            "gpt-5"
          ],
          "max_input_tokens": 400000,
          "max_output_tokens": 128000,
          "input_cost_per_token": 1.25e-06,
          "output_cost_per_token": 1e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "GPT 5 Mini",
          "submodels": [
            "gpt-5-mini"
          ],
          "max_input_tokens": 400000,
          "max_output_tokens": 128000,
          "input_cost_per_token": 2.5e-07,
          "output_cost_per_token": 2e-06,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "GPT 5 Nano",
          "submodels": [
            "gpt-5-nano"
          ],
          "max_input_tokens": 400000,
          "max_output_tokens": 128000,
          "input_cost_per_token": 5e-08,
          "output_cost_per_token": 4e-07,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        }
      ]
    },
    {
      "name": "Google AI",
      "displayName": "Google AI",
      "base_model_name": "gemini",
      "credentials_needed": {
        "api_key": {
          "type": "string",
          "displayName": "Chave de API",
          "description": "Chaven de API do Estúdio de IA da Google",
          "required": true
        }
      },
      "models": [
        {
          "displayName": "Gemini 2.0 Flash",
          "submodels": [
            "gemini-2.0-flash",
            "gemini-2.0-flash-001"
          ],
          "max_input_tokens": 1048576,
          "max_output_tokens": 8192,
          "input_cost_per_token": 1e-07,
          "output_cost_per_token": 4e-07,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Gemini 2.0 Flash Lite",
          "submodels": [
            "gemini-2.0-flash-lite"
          ],
          "max_input_tokens": 1048576,
          "max_output_tokens": 8192,
          "input_cost_per_token": 7.5e-08,
          "output_cost_per_token": 3e-07,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Gemini 2.5 Pro",
          "submodels": [
            "gemini-2.5-pro"
          ],
          "max_input_tokens": 1048576,
          "max_output_tokens": 65536,
          "input_cost_per_token": 1.25e-06,
          "output_cost_per_token": 1e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Gemini 2.5 Flash",
          "submodels": [
            "gemini-2.5-flash"
          ],
          "max_input_tokens": 1048576,
          "max_output_tokens": 65536,
          "input_cost_per_token": 3e-07,
          "output_cost_per_token": 2.5e-06,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Gemini 2.5 Flash Lite",
          "submodels": [
            "gemini-2.5-flash-lite"
          ],
          "max_input_tokens": 1048576,
          "max_output_tokens": 65536,
          "input_cost_per_token": 1e-07,
          "output_cost_per_token": 4e-07,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Gemini 3 Pro Preview",
          "submodels": [
            "gemini-3-pro-preview"
          ],
          "max_input_tokens": 1048576,
          "max_output_tokens": 65536,
          "input_cost_per_token": 2e-06,
          "output_cost_per_token": 1.2e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Gemini 3 Flash Preview",
          "submodels": [
            "gemini-3-flash-preview"
          ],
          "max_input_tokens": 1048576,
          "max_output_tokens": 65536,
          "input_cost_per_token": 5e-07,
          "output_cost_per_token": 3e-06,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        }
      ]
    },
    {
      "name": "Fireworks AI",
      "displayName": "AumoGPT",
      "base_model_name": "fireworks_ai",
      "credentials_needed": {
        "api_key": {
          "type": "string",
          "displayName": "Chave de API",
          "description": "Chave de API do AumoGPT. Entrar em contato com o suporte da AUMO para obter uma chave de API.",
          "required": true
        }
      },
      "models": [
        {
          "displayName": "GPT OSS 20B",
          "submodels": [
            "gpt-oss-20b"
          ],
          "max_input_tokens": 131072,
          "max_output_tokens": 131072,
          "input_cost_per_token": 5e-08,
          "output_cost_per_token": 2e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "GPT OSS 120b",
          "submodels": [
            "gpt-oss-120b"
          ],
          "max_input_tokens": 131072,
          "max_output_tokens": 131072,
          "input_cost_per_token": 1.5e-07,
          "output_cost_per_token": 6e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Kimi K2 Instruct",
          "submodels": [
            "kimi-k2-instruct-0905"
          ],
          "max_input_tokens": 256000,
          "max_output_tokens": 32768,
          "input_cost_per_token": 6e-07,
          "output_cost_per_token": 2.5e-06,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "DeepSeek V3.1",
          "submodels": [
            "deepseek-v3p1"
          ],
          "max_input_tokens": 160000,
          "max_output_tokens": 32768,
          "input_cost_per_token": 5.6e-07,
          "output_cost_per_token": 1.68e-06,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Deepseek v3.2",
          "submodels": [
            "deepseek-v3p2"
          ],
          "max_input_tokens": 160000,
          "max_output_tokens": 32768,
          "input_cost_per_token": 5.6e-07,
          "output_cost_per_token": 1.68e-06,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        }
      ]
    },
    {
      "name": "OCI",
      "displayName": "Oracle OCI",
      "base_model_name": "oci",
      "credentials_needed": {
        "key": {
          "type": "string",
          "displayName": "Chave Privada",
          "description": "Private Key da Oracle",
          "required": true
        },
        "user": {
          "type": "string",
          "displayName": "Usuário",
          "description": "ID do Usuário da Oracle",
          "required": true
        },
        "region": {
          "type": "string",
          "displayName": "Região",
          "description": "Nome da Região da Oracle",
          "required": true
        },
        "tenancy": {
          "type": "string",
          "displayName": "Tenancy",
          "description": "O ID do Tenant da Oracle",
          "required": true
        },
        "fingerprint": {
          "type": "string",
          "displayName": "Fingerprint",
          "description": "Oracle Fingerprint",
          "required": true
        },
        "compartment_id": {
          "type": "string",
          "displayName": "Compartment ID",
          "description": "Oracle Compartment ID",
          "required": true
        }
      },
      "models": [
        {
          "displayName": "Grok 4",
          "submodels": [
            "xai.grok-4"
          ],
          "max_tokens": 128000,
          "max_input_tokens": 128000,
          "max_output_tokens": 128000,
          "input_cost_per_token": 3e-06,
          "output_cost_per_token": 1.5e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Grok 3",
          "submodels": [
            "xai.grok-3"
          ],
          "max_input_tokens": 131072,
          "max_output_tokens": 131072,
          "input_cost_per_token": 3e-06,
          "output_cost_per_token": 1.5e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Grok 3 Fast",
          "submodels": [
            "xai.grok-3-fast"
          ],
          "max_input_tokens": 131072,
          "max_output_tokens": 131072,
          "input_cost_per_token": 5e-06,
          "output_cost_per_token": 2.5e-05,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Grok 3 Mini",
          "submodels": [
            "xai.grok-3-mini"
          ],
          "max_input_tokens": 131072,
          "max_output_tokens": 131072,
          "input_cost_per_token": 3e-07,
          "output_cost_per_token": 5e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Grok 3 Mini Fast",
          "submodels": [
            "xai.grok-3-mini-fast"
          ],
          "max_input_tokens": 131072,
          "max_output_tokens": 131072,
          "input_cost_per_token": 6e-07,
          "output_cost_per_token": 4e-06,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        }
      ]
    },
    {
      "name": "AUMO Neuron",
      "displayName": "AUMO Neuron",
      "base_model_name": "openai",
      "credentials_needed": {
        "api_key": {
          "type": "string",
          "displayName": "Chave de API",
          "description": "Chave de API da AUMO",
          "required": true
        }
      },
      "models": [
        {
          "displayName": "Qwen3-4B-aws-neuron",
          "submodels": [
            "qwen3-4b-aws-neuron"
          ],
          "max_tokens": 4096,
          "max_input_tokens": 4096,
          "max_output_tokens": 4096,
          "input_cost_per_token": 0.0,
          "output_cost_per_token": 0.0,
          "supports_function_calling": false,
          "supports_vision": false,
          "status": "active"
        }
      ]
    },
    {
      "name": "Anthropic",
      "displayName": "Anthropic",
      "base_model_name": "anthropic",
      "credentials_needed": {
        "api_key": {
          "type": "string",
          "displayName": "Chave de API",
          "description": "Chave de API da Anthropic",
          "required": true
        }
      },
      "models": [
        {
          "displayName": "Claude 3 Haiku",
          "submodels": [
            "claude-3-haiku-20240307"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 2.5e-07,
          "output_cost_per_token": 1.25e-06,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Claude 3 Opus",
          "submodels": [
            "claude-3-opus-20240229",
            "claude-3-opus-latest"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 1.5e-05,
          "output_cost_per_token": 7.5e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Claude 3.5 Haiku",
          "submodels": [
            "claude-3-5-haiku-20241022",
            "claude-3-5-haiku-latest"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 8192,
          "input_cost_per_token": 1e-06,
          "output_cost_per_token": 5e-06,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Claude 3.5 Sonnet",
          "submodels": [
            "claude-3-5-sonnet-20240620",
            "claude-3-5-sonnet-20241022",
            "claude-3-5-sonnet-latest"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 8192,
          "input_cost_per_token": 3e-06,
          "output_cost_per_token": 1.5e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Claude 3.7 Sonnet",
          "submodels": [
            "claude-3-7-sonnet-20250219",
            "claude-3-7-sonnet-latest"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 64000,
          "input_cost_per_token": 3e-06,
          "output_cost_per_token": 1.5e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Claude 4 Opus",
          "submodels": [
            "claude-4-opus-20250514"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 32000,
          "input_cost_per_token": 1.5e-05,
          "output_cost_per_token": 7.5e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Claude 4 Sonnet",
          "submodels": [
            "claude-4-sonnet-20250514"
          ],
          "max_input_tokens": 1000000,
          "max_output_tokens": 64000,
          "input_cost_per_token": 3e-06,
          "output_cost_per_token": 1.5e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Claude Haiku 4.5",
          "submodels": [
            "claude-haiku-4-5",
            "claude-haiku-4-5-20251001"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 64000,
          "input_cost_per_token": 1e-06,
          "output_cost_per_token": 5e-06,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Claude Opus 4.1",
          "submodels": [
            "claude-opus-4-1",
            "claude-opus-4-1-20250805",
            "claude-opus-4-20250514"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 32000,
          "input_cost_per_token": 1.5e-05,
          "output_cost_per_token": 7.5e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Claude Opus 4.5",
          "submodels": [
            "claude-opus-4-5",
            "claude-opus-4-5-20251101"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 64000,
          "input_cost_per_token": 5e-06,
          "output_cost_per_token": 2.5e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Claude Opus 4.6",
          "submodels": [
            "claude-opus-4-6",
            "claude-opus-4-6-20260205"
          ],
          "max_input_tokens": 1000000,
          "max_output_tokens": 128000,
          "input_cost_per_token": 5e-06,
          "output_cost_per_token": 2.5e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Claude Sonnet 4",
          "submodels": [
            "claude-sonnet-4-20250514"
          ],
          "max_input_tokens": 1000000,
          "max_output_tokens": 64000,
          "input_cost_per_token": 3e-06,
          "output_cost_per_token": 1.5e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Claude Sonnet 4.5",
          "submodels": [
            "claude-sonnet-4-5",
            "claude-sonnet-4-5-20250929"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 64000,
          "input_cost_per_token": 3e-06,
          "output_cost_per_token": 1.5e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "Claude Sonnet 4.6",
          "submodels": [
            "claude-sonnet-4-6"
          ],
          "max_input_tokens": 200000,
          "max_output_tokens": 64000,
          "input_cost_per_token": 3e-06,
          "output_cost_per_token": 1.5e-05,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        }
      ]
    }
  ]
}