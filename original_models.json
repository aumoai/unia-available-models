{
    "mock": {
        "max_tokens": 4096,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "mock",
        "mode": "chat",
        "supports_function_calling": false,
        "supports_parallel_function_calling": false,
        "supports_vision": false,
        "supports_prompt_caching": false,
        "supports_system_messages": false,
        "supports_tool_choice": false,
        "supports_response_schema": false,
        "supports_web_search": false,
        "search_context_cost_per_query": {
            "search_context_size_low": 0.0,
            "search_context_size_medium": 0.0,
            "search_context_size_high": 0.0
        },
        "cache_read_input_token_cost": 0.0
    },
    "gpt-4": {
        "max_tokens": 4096, 
        "max_input_tokens": 8192,
        "max_output_tokens": 4096, 
        "input_cost_per_token": 0.00003,
        "output_cost_per_token": 0.00006,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 0.0000025,
        "output_cost_per_token": 0.000010,
        "input_cost_per_token_batches": 0.00000125,
        "output_cost_per_token_batches": 0.00000500,
        "cache_read_input_token_cost": 0.00000125,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_web_search": true,
        "search_context_cost_per_query": {
            "search_context_size_low": 0.030,
            "search_context_size_medium": 0.035,
            "search_context_size_high": 0.050
        }
    },
    "gpt-4.5-preview": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 0.000075,
        "output_cost_per_token": 0.00015,
        "input_cost_per_token_batches": 0.0000375,
        "output_cost_per_token_batches": 0.000075,
        "cache_read_input_token_cost": 0.0000375,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4.5-preview-2025-02-27": {
        "model_version_date": true,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 0.000075,
        "output_cost_per_token": 0.00015,
        "input_cost_per_token_batches": 0.0000375,
        "output_cost_per_token_batches": 0.000075,
        "cache_read_input_token_cost": 0.0000375,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-mini": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 0.00000015,
        "output_cost_per_token": 0.00000060,
        "input_cost_per_token_batches": 0.000000075,
        "output_cost_per_token_batches": 0.00000030,
        "cache_read_input_token_cost": 0.000000075,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_web_search": true,
        "search_context_cost_per_query": {
            "search_context_size_low": 0.025,
            "search_context_size_medium": 0.0275,
            "search_context_size_high": 0.030
        }
    },
    "gpt-4o-mini-2024-07-18": {
        "model_version_date": true,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 0.00000015,
        "output_cost_per_token": 0.00000060,
        "input_cost_per_token_batches": 0.000000075,
        "output_cost_per_token_batches": 0.00000030,
        "cache_read_input_token_cost": 0.000000075,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "search_context_cost_per_query": {
            "search_context_size_low": 30.00,
            "search_context_size_medium": 35.00,
            "search_context_size_high": 50.00
        }
    },
    "o1": {
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "input_cost_per_token": 0.000015,
        "output_cost_per_token": 0.00006,
        "cache_read_input_token_cost": 0.0000075,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "o1-mini": {
        "max_tokens": 65536,
        "max_input_tokens": 128000,
        "max_output_tokens": 65536,
        "input_cost_per_token": 0.0000011,
        "output_cost_per_token": 0.0000044,
        "cache_read_input_token_cost": 0.00000055,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_vision": true,
        "supports_prompt_caching": true
    },
    "o3-mini": {
        "model_version_date": true,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "input_cost_per_token": 0.0000011,
        "output_cost_per_token": 0.0000044,
        "cache_read_input_token_cost": 0.00000055,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_vision": false,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "o3-mini-2025-01-31": {
        "model_version_date": true,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "input_cost_per_token": 0.0000011,
        "output_cost_per_token": 0.0000044,
        "cache_read_input_token_cost": 0.00000055,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_vision": false,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "o1-mini-2024-09-12": {
        "model_version_date": true,
        "max_tokens": 65536,
        "max_input_tokens": 128000,
        "max_output_tokens": 65536,
        "input_cost_per_token": 0.000003,
        "output_cost_per_token": 0.000012,
        "cache_read_input_token_cost": 0.0000015,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_vision": true,
        "supports_prompt_caching": true
    },
    "o1-preview": {
        "max_tokens": 32768,
        "max_input_tokens": 128000,
        "max_output_tokens": 32768,
        "input_cost_per_token": 0.000015,
        "output_cost_per_token": 0.000060,
        "cache_read_input_token_cost": 0.0000075,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_vision": true,
        "supports_prompt_caching": true
    },
    "o1-preview-2024-09-12": {
        "max_tokens": 32768,
        "max_input_tokens": 128000,
        "max_output_tokens": 32768,
        "input_cost_per_token": 0.000015,
        "output_cost_per_token": 0.000060,
        "cache_read_input_token_cost": 0.0000075,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_vision": true,
        "supports_prompt_caching": true
    },
    "o1-2024-12-17": {
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "input_cost_per_token": 0.000015,
        "output_cost_per_token": 0.000060,
        "cache_read_input_token_cost": 0.0000075,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "chatgpt-4o-latest": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.000005,
        "output_cost_per_token": 0.000015,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-2024-05-13": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.000005,
        "output_cost_per_token": 0.000015,
        "input_cost_per_token_batches": 0.0000025,
        "output_cost_per_token_batches": 0.0000075,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-2024-08-06": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 0.0000025,
        "output_cost_per_token": 0.000010,
        "input_cost_per_token_batches": 0.00000125,
        "output_cost_per_token_batches": 0.0000050,
        "cache_read_input_token_cost": 0.00000125,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_web_search": true,
        "search_context_cost_per_query": {
            "search_context_size_low": 0.030,
            "search_context_size_medium": 0.035,
            "search_context_size_high": 0.050
        }
    },
    "gpt-4o-2024-11-20": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 0.0000025,
        "output_cost_per_token": 0.000010,
        "input_cost_per_token_batches": 0.00000125,
        "output_cost_per_token_batches": 0.0000050,
        "cache_read_input_token_cost": 0.00000125,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-turbo-preview": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00001,
        "output_cost_per_token": 0.00003,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-0314": {
        "model_version_date": true,
        "max_tokens": 4096,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00003,
        "output_cost_per_token": 0.00006,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-0613": {
        "model_version_date": true,
        "max_tokens": 4096,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00003,
        "output_cost_per_token": 0.00006,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "deprecation_date": "2025-06-06",
        "supports_tool_choice": true
    },
    "gpt-4-32k": {
        "max_tokens": 4096,
        "max_input_tokens": 32768,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00006,
        "output_cost_per_token": 0.00012,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-32k-0314": {
        "model_version_date": true,
        "max_tokens": 4096,
        "max_input_tokens": 32768,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00006,
        "output_cost_per_token": 0.00012,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-32k-0613": {
        "model_version_date": true,
        "max_tokens": 4096,
        "max_input_tokens": 32768,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00006,
        "output_cost_per_token": 0.00012,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-turbo": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00001,
        "output_cost_per_token": 0.00003,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-turbo-2024-04-09": {
        "model_version_date": true,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00001,
        "output_cost_per_token": 0.00003,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-1106-preview": {
        "model_version_date": true,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00001,
        "output_cost_per_token": 0.00003,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-0125-preview": {
        "model_version_date": true,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00001,
        "output_cost_per_token": 0.00003,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-vision-preview": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00001,
        "output_cost_per_token": 0.00003,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "deprecation_date": "2024-12-06",
        "supports_tool_choice": true
    },
    "gpt-4-1106-vision-preview": {
        "model_version_date": true,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00001,
        "output_cost_per_token": 0.00003,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "deprecation_date": "2024-12-06",
        "supports_tool_choice": true
    },
    "gpt-3.5-turbo": {
        "max_tokens": 4097,
        "max_input_tokens": 16385,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.0000015,
        "output_cost_per_token": 0.000002,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-3.5-turbo-0301": {
        "model_version_date": true,
        "max_tokens": 4097,
        "max_input_tokens": 4097,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.0000015,
        "output_cost_per_token": 0.000002,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-3.5-turbo-0613": {
        "model_version_date": true,
        "max_tokens": 4097,
        "max_input_tokens": 4097,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.0000015,
        "output_cost_per_token": 0.000002,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-3.5-turbo-1106": {
        "model_version_date": true,
        "max_tokens": 16385,
        "max_input_tokens": 16385,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.0000010,
        "output_cost_per_token": 0.0000020,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-3.5-turbo-0125": {
        "model_version_date": true,
        "max_tokens": 16385,
        "max_input_tokens": 16385,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.0000005,
        "output_cost_per_token": 0.0000015,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-3.5-turbo-16k": {
        "max_tokens": 16385,
        "max_input_tokens": 16385,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.000003,
        "output_cost_per_token": 0.000004,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-3.5-turbo-16k-0613": {
        "model_version_date": true,
        "max_tokens": 16385,
        "max_input_tokens": 16385,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.000003,
        "output_cost_per_token": 0.000004,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "azure/o3-mini-2025-01-31": {
        "model_version_date": true,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "input_cost_per_token": 0.0000011,
        "output_cost_per_token": 0.0000044,
        "cache_read_input_token_cost": 0.00000055,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_vision": false,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/o3-mini": {
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "input_cost_per_token": 0.0000011,
        "output_cost_per_token": 0.0000044,
        "cache_read_input_token_cost": 0.00000055,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_vision": false,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "azure/o1-mini": {
        "max_tokens": 65536,
        "max_input_tokens": 128000,
        "max_output_tokens": 65536,
        "input_cost_per_token": 0.00000121,
        "output_cost_per_token": 0.00000484,
        "cache_read_input_token_cost": 0.000000605,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false,
        "supports_prompt_caching": true
    },
    "azure/o1-mini-2024-09-12": {
        "model_version_date": true,
        "max_tokens": 65536,
        "max_input_tokens": 128000,
        "max_output_tokens": 65536,
        "input_cost_per_token": 0.00000121,
        "output_cost_per_token": 0.00000484,
        "cache_read_input_token_cost": 0.000000605,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false,
        "supports_prompt_caching": true
    },
    "azure/o1": {
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "input_cost_per_token": 0.000015,
        "output_cost_per_token": 0.000060,
        "cache_read_input_token_cost": 0.0000075,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/o1-2024-12-17": {
        "model_version_date": true,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "input_cost_per_token": 0.000015,
        "output_cost_per_token": 0.000060,
        "cache_read_input_token_cost": 0.0000075,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/o1-preview": {
        "max_tokens": 32768,
        "max_input_tokens": 128000,
        "max_output_tokens": 32768,
        "input_cost_per_token": 0.000015,
        "output_cost_per_token": 0.000060,
        "cache_read_input_token_cost": 0.0000075,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false,
        "supports_prompt_caching": true
    },
    "azure/o1-preview-2024-09-12": {
        "model_version_date": true,
        "max_tokens": 32768,
        "max_input_tokens": 128000,
        "max_output_tokens": 32768,
        "input_cost_per_token": 0.000015,
        "output_cost_per_token": 0.000060,
        "cache_read_input_token_cost": 0.0000075,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false,
        "supports_prompt_caching": true
    },
    "azure/us/o1-preview-2024-09-12": {
        "model_version_date": true,
        "max_tokens": 32768,
        "max_input_tokens": 128000,
        "max_output_tokens": 32768,
        "input_cost_per_token": 0.0000165,
        "output_cost_per_token": 0.000066,
        "cache_read_input_token_cost": 0.00000825,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false,
        "supports_prompt_caching": true
    },
    "azure/gpt-4.5-preview": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 0.000075,
        "output_cost_per_token": 0.00015,
        "input_cost_per_token_batches": 0.0000375,
        "output_cost_per_token_batches": 0.000075,
        "cache_read_input_token_cost": 0.0000375,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4o": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 0.0000025,
        "output_cost_per_token": 0.00001,
        "cache_read_input_token_cost": 0.00000125,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/global/gpt-4o-2024-11-20": {
        "model_version_date": true,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 0.0000025,
        "output_cost_per_token": 0.00001,
        "cache_read_input_token_cost": 0.00000125,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4o-2024-08-06": {
        "model_version_date": true,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 0.0000025,
        "output_cost_per_token": 0.00001,
        "cache_read_input_token_cost": 0.00000125,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4o-2024-11-20": {
        "model_version_date": true,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 0.00000275,
        "output_cost_per_token": 0.000011,
        "cache_read_input_token_cost": 0.00000125,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4o-2024-05-13": {
        "model_version_date": true,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.000005,
        "output_cost_per_token": 0.000015,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4o-mini": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 0.000000165,
        "output_cost_per_token": 0.00000066,
        "cache_read_input_token_cost": 0.000000075,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4o-mini-2024-07-18": {
        "model_version_date": true,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 0.000000165,
        "output_cost_per_token": 0.00000066,
        "cache_read_input_token_cost": 0.000000075,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4-turbo-2024-04-09": {
        "model_version_date": true,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00001,
        "output_cost_per_token": 0.00003,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4-0125-preview": {
        "model_version_date": true,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00001,
        "output_cost_per_token": 0.00003,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4-1106-preview": {
        "model_version_date": true,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00001,
        "output_cost_per_token": 0.00003,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4-0613": {
        "model_version_date": true,
        "max_tokens": 4096,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00003,
        "output_cost_per_token": 0.00006,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4-32k-0613": {
        "model_version_date": true,
        "max_tokens": 4096,
        "max_input_tokens": 32768,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00006,
        "output_cost_per_token": 0.00012,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "azure/gpt-4-32k": {
        "max_tokens": 4096,
        "max_input_tokens": 32768,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00006,
        "output_cost_per_token": 0.00012,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "azure/gpt-4": {
        "max_tokens": 4096,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00003,
        "output_cost_per_token": 0.00006,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4-turbo": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00001,
        "output_cost_per_token": 0.00003,
        "litellm_provider": "azure", 
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4-turbo-vision-preview": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00001,
        "output_cost_per_token": 0.00003,
        "litellm_provider": "azure", 
        "mode": "chat",
        "supports_vision": true,
        "supports_tool_choice": true
    },
    "azure/gpt-35-turbo-16k-0613": {
        "model_version_date": true,
        "max_tokens": 4096,
        "max_input_tokens": 16385,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.000003,
        "output_cost_per_token": 0.000004,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "azure/gpt-35-turbo-1106": {
        "model_version_date": true,
        "max_tokens": 4096,
        "max_input_tokens": 16384,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.000001,
        "output_cost_per_token": 0.000002,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "deprecation_date": "2025-03-31",
        "supports_tool_choice": true
    },
    "azure/gpt-35-turbo-0613": {
        "model_version_date": true,
        "max_tokens": 4097,
        "max_input_tokens": 4097,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.0000015,
        "output_cost_per_token": 0.000002,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "deprecation_date": "2025-02-13",
        "supports_tool_choice": true
    },
    "azure/gpt-35-turbo-0301": {
        "model_version_date": true,
        "max_tokens": 4097,
        "max_input_tokens": 4097,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.0000002,
        "output_cost_per_token": 0.000002,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "deprecation_date": "2025-02-13",
        "supports_tool_choice": true
    },
    "azure/gpt-35-turbo-0125": {
        "model_version_date": true,
        "max_tokens": 4096,
        "max_input_tokens": 16384,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.0000005,
        "output_cost_per_token": 0.0000015,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "deprecation_date": "2025-05-31",
        "supports_tool_choice": true
    },
    "azure/gpt-3.5-turbo-0125": {
        "model_version_date": true,
        "max_tokens": 4096,
        "max_input_tokens": 16384,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.0000005,
        "output_cost_per_token": 0.0000015,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "deprecation_date": "2025-03-31",
        "supports_tool_choice": true
    },
    "azure/gpt-35-turbo-16k": {
        "max_tokens": 4096,
        "max_input_tokens": 16385,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.000003,
        "output_cost_per_token": 0.000004,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "azure/gpt-35-turbo": {
        "max_tokens": 4096,
        "max_input_tokens": 4097,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.0000005,
        "output_cost_per_token": 0.0000015,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "azure/gpt-3.5-turbo": {
        "max_tokens": 4096,
        "max_input_tokens": 4097,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.0000005,
        "output_cost_per_token": 0.0000015,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "azure/gpt-3.5-turbo-instruct-0914": {
        "model_version_date": true,
        "max_tokens": 4097,
        "max_input_tokens": 4097,
        "input_cost_per_token": 0.0000015,
        "output_cost_per_token": 0.000002,
        "litellm_provider": "azure_text",
        "mode": "completion"
    },
    "azure/gpt-35-turbo-instruct": {
        "max_tokens": 4097,
        "max_input_tokens": 4097,
        "input_cost_per_token": 0.0000015,
        "output_cost_per_token": 0.000002,
        "litellm_provider": "azure_text",
        "mode": "completion"
    },
    "azure/gpt-35-turbo-instruct-0914": {
        "model_version_date": true,
        "max_tokens": 4097,
        "max_input_tokens": 4097,
        "input_cost_per_token": 0.0000015,
        "output_cost_per_token": 0.000002,
        "litellm_provider": "azure_text",
        "mode": "completion"
    },
    "azure/mistral-large-latest": {
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "input_cost_per_token": 0.000008,
        "output_cost_per_token": 0.000024,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true
    },
    "azure/mistral-large-2402": {
        "model_version_date": true,
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "input_cost_per_token": 0.000008,
        "output_cost_per_token": 0.000024,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true
    },
    "azure/command-r-plus": {
        "max_tokens": 4096, 
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.000003,
        "output_cost_per_token": 0.000015,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true
    },
    "azure_ai/deepseek-r1": {
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0.00000135,
        "output_cost_per_token": 0.0000054,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_tool_choice": true,
        "source": "https://techcommunity.microsoft.com/blog/machinelearningblog/deepseek-r1-improved-performance-higher-limits-and-transparent-pricing/4386367"
    },
    "azure_ai/deepseek-v3": {
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0.00000114,
        "output_cost_per_token": 0.00000456,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_tool_choice": true,
        "source": "https://techcommunity.microsoft.com/blog/machinelearningblog/announcing-deepseek-v3-on-azure-ai-foundry-and-github/4390438"
    },
    "azure_ai/jamba-instruct": {
        "max_tokens": 4096,
        "max_input_tokens": 70000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.0000005,
        "output_cost_per_token": 0.0000007,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "azure_ai/mistral-nemo": {
        "max_tokens": 4096,
        "max_input_tokens": 131072,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00000015,
        "output_cost_per_token": 0.00000015,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_function_calling": true,
        "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-nemo-12b-2407?tab=PlansAndPrice"
    },
    "azure_ai/mistral-large": {
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 0.000004,
        "output_cost_per_token": 0.000012,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "azure_ai/mistral-small": {
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 0.000001,
        "output_cost_per_token": 0.000003,
        "litellm_provider": "azure_ai",
        "supports_function_calling": true,
        "mode": "chat",
        "supports_tool_choice": true
    },
    "azure_ai/mistral-small-2503": {
        "model_version_date": true,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 0.000001,
        "output_cost_per_token": 0.000003,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_tool_choice": true
    },
    "azure_ai/mistral-large-2407": {
        "model_version_date": true,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.000002,
        "output_cost_per_token": 0.000006,
        "litellm_provider": "azure_ai",
        "supports_function_calling": true,
        "mode": "chat",
        "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-ai-large-2407-offer?tab=Overview",
        "supports_tool_choice": true
    },
    "azure_ai/ministral-3b": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00000004,
        "output_cost_per_token": 0.00000004,
        "litellm_provider": "azure_ai",
        "supports_function_calling": true,
        "mode": "chat",
        "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.ministral-3b-2410-offer?tab=Overview",
        "supports_tool_choice": true
    },    
    "azure_ai/Llama-3.2-11B-Vision-Instruct": {
        "max_tokens": 2048,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "input_cost_per_token": 0.00000037,
        "output_cost_per_token": 0.00000037,
        "litellm_provider": "azure_ai",
        "supports_function_calling": true,
        "supports_vision": true,
        "mode": "chat",
        "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-11b-vision-instruct-offer?tab=Overview",
        "supports_tool_choice": true
    },
    "azure_ai/Llama-3.3-70B-Instruct": {
        "max_tokens": 2048,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "input_cost_per_token": 0.00000071,
        "output_cost_per_token": 0.00000071,
        "litellm_provider": "azure_ai",
        "supports_function_calling": true,
        "mode": "chat",
        "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.llama-3-3-70b-instruct-offer?tab=Overview",
        "supports_tool_choice": true
    },
    "azure_ai/Llama-3.2-90B-Vision-Instruct": {
        "max_tokens": 2048,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "input_cost_per_token": 0.00000204,
        "output_cost_per_token": 0.00000204,
        "litellm_provider": "azure_ai",
        "supports_function_calling": true,
        "supports_vision": true,
        "mode": "chat",
        "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-90b-vision-instruct-offer?tab=Overview",
        "supports_tool_choice": true
    },
    "azure_ai/Meta-Llama-3-70B-Instruct": {
        "max_tokens": 2048,
        "max_input_tokens": 8192,
        "max_output_tokens": 2048,
        "input_cost_per_token": 0.0000011,
        "output_cost_per_token": 0.00000037,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "azure_ai/Meta-Llama-3.1-8B-Instruct": {
        "max_tokens": 2048,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "input_cost_per_token": 0.0000003,
        "output_cost_per_token": 0.00000061,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "source":"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-8b-instruct-offer?tab=PlansAndPrice",
        "supports_tool_choice": true
    },
    "azure_ai/Meta-Llama-3.1-70B-Instruct": {
        "max_tokens": 2048,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "input_cost_per_token": 0.00000268,
        "output_cost_per_token": 0.00000354,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "source":"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-70b-instruct-offer?tab=PlansAndPrice",
        "supports_tool_choice": true
    },
    "azure_ai/Meta-Llama-3.1-405B-Instruct": {
        "max_tokens": 2048,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "input_cost_per_token": 0.00000533,
        "output_cost_per_token": 0.000016,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "source":"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-405b-instruct-offer?tab=PlansAndPrice",
        "supports_tool_choice": true
    },
    "azure_ai/Phi-4-mini-instruct": {
        "max_tokens": 4096,
        "max_input_tokens": 131072,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_function_calling": true,
        "source": "https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/models-featured#microsoft"
    },
    "azure_ai/Phi-4-multimodal-instruct": {
        "max_tokens": 4096,
        "max_input_tokens": 131072,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_audio_input": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "source": "https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/models-featured#microsoft"
    },
    "azure_ai/Phi-4": {
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "input_cost_per_token": 0.000000125,
        "output_cost_per_token": 0.0000005,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_vision": false,
        "source": "https://techcommunity.microsoft.com/blog/machinelearningblog/affordable-innovation-unveiling-the-pricing-of-phi-3-slms-on-models-as-a-service/4156495",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "azure_ai/Phi-3.5-mini-instruct": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00000013,
        "output_cost_per_token": 0.00000052,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_vision": false,
        "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
        "supports_tool_choice": true
    },
    "azure_ai/Phi-3.5-vision-instruct": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00000013,
        "output_cost_per_token": 0.00000052,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_vision": true,
        "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
        "supports_tool_choice": true
    },
    "azure_ai/Phi-3.5-MoE-instruct": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00000016,
        "output_cost_per_token": 0.00000064,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_vision": false,
        "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
        "supports_tool_choice": true
    },
    "azure_ai/Phi-3-mini-4k-instruct": {
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00000013,
        "output_cost_per_token": 0.00000052,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_vision": false,
        "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
        "supports_tool_choice": true
    },
    "azure_ai/Phi-3-mini-128k-instruct": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00000013,
        "output_cost_per_token": 0.00000052,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_vision": false,
        "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
        "supports_tool_choice": true
    },
    "azure_ai/Phi-3-small-8k-instruct": {
        "max_tokens": 4096,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00000015,
        "output_cost_per_token": 0.0000006,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_vision": false,
        "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
        "supports_tool_choice": true
    },
    "azure_ai/Phi-3-small-128k-instruct": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00000015,
        "output_cost_per_token": 0.0000006,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_vision": false,
        "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
        "supports_tool_choice": true
    },
    "azure_ai/Phi-3-medium-4k-instruct": {
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00000017,
        "output_cost_per_token": 0.00000068,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_vision": false,
        "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
        "supports_tool_choice": true
    },
    "azure_ai/Phi-3-medium-128k-instruct": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00000017,
        "output_cost_per_token": 0.00000068,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_vision": false,
        "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
        "supports_tool_choice": true
    },
    "gpt-3.5-turbo-instruct": {
        "max_tokens": 4096,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.0000015,
        "output_cost_per_token": 0.000002,
        "litellm_provider": "text-completion-openai",
        "mode": "completion"
    },
    "gpt-3.5-turbo-instruct-0914": {
        "model_version_date": true,
        "max_tokens": 4097,
        "max_input_tokens": 8192,
        "max_output_tokens": 4097,
        "input_cost_per_token": 0.0000015,
        "output_cost_per_token": 0.000002,
        "litellm_provider": "text-completion-openai",
        "mode": "completion"

    },

    "gemini/gemma-3n-e4b-it": {
        "max_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0.00000035, 
        "output_cost_per_token": 0.00000105, 
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_tool_choice": true
    },
    "gemini/gemini-2.0-pro-exp-02-05": {
        "model_version_date": true,
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_image": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_token": 0,
        "input_cost_per_character": 0, 
        "input_cost_per_token_above_128k_tokens": 0, 
        "input_cost_per_character_above_128k_tokens": 0, 
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_character": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "rpm": 2,
        "tpm": 1000000,
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_audio_input": true,
        "supports_video_input": true,
        "supports_pdf_input": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    "gemini/gemini-2.0-flash": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_audio_token": 0.0000007,
        "input_cost_per_token": 0.0000001,
        "output_cost_per_token": 0.0000004,
        "litellm_provider": "gemini",
        "mode": "chat",
        "rpm": 10000,
        "tpm": 10000000,
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": true,
        "supports_audio_input": true,
        "supported_modalities": ["text", "image", "audio", "video"],
        "supports_tool_choice": true,
        "source": "https://ai.google.dev/pricing#2_0flash"
    },
    "gemini/gemini-2.0-flash-lite": {
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 50,
        "input_cost_per_audio_token": 0.000000075,
        "input_cost_per_token": 0.000000075,
        "output_cost_per_token": 0.0000003,
        "litellm_provider": "gemini",
        "mode": "chat",
        "tpm": 4000000,
        "rpm": 4000,
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": true,
        "supports_tool_choice": true,
        "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.0-flash-lite"
    },
    "gemini/gemini-2.0-flash-001": {
        "model_version_date": true,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_audio_token": 0.0000007,
        "input_cost_per_token": 0.0000001,
        "output_cost_per_token": 0.0000004,
        "litellm_provider": "gemini",
        "mode": "chat",
        "rpm": 10000,
        "tpm": 10000000,
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": false,
        "supports_tool_choice": true,
        "source": "https://ai.google.dev/pricing#2_0flash"
    },
    "gemini/gemini-2.0-flash-exp": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_image": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_token": 0,
        "input_cost_per_character": 0, 
        "input_cost_per_token_above_128k_tokens": 0, 
        "input_cost_per_character_above_128k_tokens": 0, 
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_character": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": true,
        "tpm": 4000000,
        "rpm": 10,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
        "supports_tool_choice": true
    },
    "gemini/gemini-2.0-flash-lite-preview-02-05": {
        "model_version_date": true,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_audio_token": 0.000000075,
        "input_cost_per_token": 0.000000075,
        "output_cost_per_token": 0.0000003,
        "litellm_provider": "gemini",
        "mode": "chat",
        "rpm": 60000,
        "tpm": 10000000,
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": false,
        "supports_tool_choice": true,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash-lite"
    },
    "gemini/gemini-2.0-flash-thinking-exp": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65536,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_image": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_token": 0,
        "input_cost_per_character": 0, 
        "input_cost_per_token_above_128k_tokens": 0, 
        "input_cost_per_character_above_128k_tokens": 0, 
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_character": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": true,
        "tpm": 4000000,
        "rpm": 10,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
        "supports_tool_choice": true
    },
    "gemini/gemini-2.0-flash-thinking-exp-01-21": {
        "model_version_date": true,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65536,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_image": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_token": 0,
        "input_cost_per_character": 0, 
        "input_cost_per_token_above_128k_tokens": 0, 
        "input_cost_per_character_above_128k_tokens": 0, 
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_character": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": true,
        "tpm": 4000000,
        "rpm": 10,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
        "supports_tool_choice": true
    },
    "gemini/gemma-3-27b-it": {
        "max_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0.00000035, 
        "output_cost_per_token": 0.00000105, 
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_tool_choice": true
    },
    "gemini/gemini-1.5-flash-002": {
        "model_version_date": true,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30, 
        "cache_read_input_token_cost": 0.00000001875,
        "cache_creation_input_token_cost": 0.000001,
        "input_cost_per_token": 0.000000075,
        "input_cost_per_token_above_128k_tokens": 0.00000015,
        "output_cost_per_token": 0.0000003,
        "output_cost_per_token_above_128k_tokens": 0.0000006,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_prompt_caching": true,
        "tpm": 4000000,
        "rpm": 2000,
        "source": "https://ai.google.dev/pricing",
        "deprecation_date": "2025-09-24",
        "supports_tool_choice": true
    },
    "gemini/gemini-1.5-flash-001": {
        "model_version_date": true,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30, 
        "cache_read_input_token_cost": 0.00000001875,
        "cache_creation_input_token_cost": 0.000001,
        "input_cost_per_token": 0.000000075,
        "input_cost_per_token_above_128k_tokens": 0.00000015,
        "output_cost_per_token": 0.0000003,
        "output_cost_per_token_above_128k_tokens": 0.0000006,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_prompt_caching": true,
        "tpm": 4000000,
        "rpm": 2000,
        "source": "https://ai.google.dev/pricing",
        "deprecation_date": "2025-05-24",
        "supports_tool_choice": true
    },
    "gemini/gemini-1.5-flash": {
        "model_version_date": true,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30, 
        "input_cost_per_token": 0.000000075,
        "input_cost_per_token_above_128k_tokens": 0.00000015,
        "output_cost_per_token": 0.0000003,
        "output_cost_per_token_above_128k_tokens": 0.0000006,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true, 
        "tpm": 4000000,
        "rpm": 2000,
        "source": "https://ai.google.dev/pricing",
        "supports_tool_choice": true
    },
    "gemini/gemini-1.5-flash-latest": {
        "model_version_date": true,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30, 
        "input_cost_per_token": 0.000000075,
        "input_cost_per_token_above_128k_tokens": 0.00000015,
        "output_cost_per_token": 0.0000003,
        "output_cost_per_token_above_128k_tokens": 0.0000006,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_prompt_caching": true,
        "tpm": 4000000,
        "rpm": 2000,
        "source": "https://ai.google.dev/pricing",
        "supports_tool_choice": true
    },
    "gemini/gemini-1.5-flash-8b": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30, 
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_prompt_caching": true,
        "tpm": 4000000,
        "rpm": 4000,
        "source": "https://ai.google.dev/pricing",
        "supports_tool_choice": true
    },
    "gemini/gemini-1.5-flash-8b-exp-0924": {
        "model_version_date": true,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30, 
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_prompt_caching": true,
        "tpm": 4000000,
        "rpm": 4000,
        "source": "https://ai.google.dev/pricing",
        "supports_tool_choice": true
    },
    "gemini/gemini-exp-1114": {
        "model_version_date": true,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30, 
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "tpm": 4000000,
        "rpm": 1000,
        "source": "https://ai.google.dev/pricing",
        "metadata": {
            "notes": "Rate limits not documented for gemini-exp-1114. Assuming same as gemini-1.5-pro.",
            "supports_tool_choice": true
        }
    },
    "gemini/gemini-exp-1206": {
        "model_version_date": true,
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30, 
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "tpm": 4000000,
        "rpm": 1000,
        "source": "https://ai.google.dev/pricing",
        "metadata": {
            "notes": "Rate limits not documented for gemini-exp-1206. Assuming same as gemini-1.5-pro.",
            "supports_tool_choice": true
        }
    },
    "gemini/gemini-1.5-flash-exp-0827": {
        "model_version_date": true,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30, 
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "tpm": 4000000,
        "rpm": 2000,
        "source": "https://ai.google.dev/pricing",
        "supports_tool_choice": true
    },
    "gemini/gemini-1.5-flash-8b-exp-0827": {
        "model_version_date": true,
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30, 
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "tpm": 4000000,
        "rpm": 4000,
        "source": "https://ai.google.dev/pricing",
        "supports_tool_choice": true
    },
    "gemini/gemini-pro": {
        "max_tokens": 8192,
        "max_input_tokens": 32760,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0.00000035, 
        "input_cost_per_token_above_128k_tokens": 0.0000007, 
        "output_cost_per_token": 0.00000105, 
        "output_cost_per_token_above_128k_tokens": 0.0000021, 
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_function_calling": true,
        "rpd": 30000,
        "tpm": 120000,
        "rpm": 360,
        "source": "https://ai.google.dev/gemini-api/docs/models/gemini",
        "supports_tool_choice": true
    },
    "gemini/gemini-1.5-pro": {
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0.0000035, 
        "input_cost_per_token_above_128k_tokens": 0.000007, 
        "output_cost_per_token": 0.0000105, 
        "output_cost_per_token_above_128k_tokens": 0.000021, 
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_tool_choice": true, 
        "supports_response_schema": true, 
        "tpm": 4000000,
        "rpm": 1000,
        "source": "https://ai.google.dev/pricing"
    },
    "gemini/gemini-1.5-pro-002": {
        "model_version_date": true,
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0.0000035, 
        "input_cost_per_token_above_128k_tokens": 0.000007, 
        "output_cost_per_token": 0.0000105, 
        "output_cost_per_token_above_128k_tokens": 0.000021, 
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_tool_choice": true, 
        "supports_response_schema": true, 
        "supports_prompt_caching": true,
        "tpm": 4000000,
        "rpm": 1000,
        "source": "https://ai.google.dev/pricing",
        "deprecation_date": "2025-09-24"
    },
    "gemini/gemini-1.5-pro-001": {
        "model_version_date": true,
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0.0000035, 
        "input_cost_per_token_above_128k_tokens": 0.000007, 
        "output_cost_per_token": 0.0000105, 
        "output_cost_per_token_above_128k_tokens": 0.000021, 
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_tool_choice": true, 
        "supports_response_schema": true, 
        "supports_prompt_caching": true,
        "tpm": 4000000,
        "rpm": 1000,
        "source": "https://ai.google.dev/pricing",
        "deprecation_date": "2025-05-24"
    },
    "gemini/gemini-1.5-pro-exp-0801": {
        "model_version_date": true,
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0.0000035,
        "input_cost_per_token_above_128k_tokens": 0.000007,
        "output_cost_per_token": 0.0000105,
        "output_cost_per_token_above_128k_tokens": 0.000021,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_tool_choice": true,
        "supports_response_schema": true,
        "tpm": 4000000,
        "rpm": 1000,
        "source": "https://ai.google.dev/pricing"
    },
    "gemini/gemini-1.5-pro-exp-0827": {
        "model_version_date": true,
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_tool_choice": true,
        "supports_response_schema": true,
        "tpm": 4000000,
        "rpm": 1000,
        "source": "https://ai.google.dev/pricing"
    },
    "gemini/gemini-1.5-pro-latest": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0.0000035, 
        "input_cost_per_token_above_128k_tokens": 0.000007, 
        "output_cost_per_token": 0.00000105, 
        "output_cost_per_token_above_128k_tokens": 0.000021, 
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_tool_choice": true, 
        "supports_response_schema": true, 
        "tpm": 4000000,
        "rpm": 1000,
        "source": "https://ai.google.dev/pricing"
    },
    "gemini/gemini-pro-vision": {
        "max_tokens": 2048,
        "max_input_tokens": 30720,
        "max_output_tokens": 2048,
        "input_cost_per_token": 0.00000035, 
        "input_cost_per_token_above_128k_tokens": 0.0000007, 
        "output_cost_per_token": 0.00000105, 
        "output_cost_per_token_above_128k_tokens": 0.0000021, 
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "rpd": 30000,
        "tpm": 120000,
        "rpm": 360,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_tool_choice": true
    },
    "gemini/gemini-gemma-2-27b-it": {
        "max_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0.00000035, 
        "output_cost_per_token": 0.00000105, 
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_tool_choice": true
    },
    "gemini/gemini-gemma-2-9b-it": {
        "max_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0.00000035, 
        "output_cost_per_token": 0.00000105, 
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_tool_choice": true
    },
    "gemini/gemini-2.5-pro-preview-05-06": {
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_audio_token": 7e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_200k_tokens": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_above_200k_tokens": 1.5e-05,
        "litellm_provider": "gemini",
        "mode": "chat",
        "rpm": 10000,
        "tpm": 10000000,
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": false,
        "supports_tool_choice": true,
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview",
        "supports_web_search": true,
        "supports_url_context": true
    },
    "gemini/gemini-2.5-pro-preview-03-25": {
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_audio_token": 7e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_200k_tokens": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_above_200k_tokens": 1.5e-05,
        "litellm_provider": "gemini",
        "mode": "chat",
        "rpm": 10000,
        "tpm": 10000000,
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": false,
        "supports_tool_choice": true,
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview",
        "supports_web_search": true
    },
    "gemini/gemini-2.5-flash-preview-05-20": {
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_audio_token": 1e-06,
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "output_cost_per_reasoning_token": 3.5e-06,
        "litellm_provider": "gemini",
        "mode": "chat",
        "rpm": 10,
        "tpm": 250000,
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_audio_output": false,
        "supports_tool_choice": true,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
        "supports_web_search": true,
        "supports_url_context": true
    },
    "gemini/gemini-2.5-flash-preview-04-17": {
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_audio_token": 1e-06,
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "output_cost_per_reasoning_token": 3.5e-06,
        "litellm_provider": "gemini",
        "mode": "chat",
        "rpm": 10,
        "tpm": 250000,
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_audio_output": false,
        "supports_tool_choice": true,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
        "supports_web_search": true
    },
    "gemini-2.5-flash-preview-05-20": {
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_audio_token": 1e-06,
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "output_cost_per_reasoning_token": 3.5e-06,
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "supports_reasoning": true,
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": false,
        "supports_tool_choice": true,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
        "supports_parallel_function_calling": true,
        "supports_web_search": true,
        "supports_url_context": true
    },

    "oci/meta.llama-4-maverick-17b-128e-instruct-fp8": {
        "max_tokens": 512000,
        "max_input_tokens": 512000,
        "max_output_tokens": 4000,
        "input_cost_per_token": 7.2e-07,
        "output_cost_per_token": 7.2e-07,
        "litellm_provider": "oci",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": false,
        "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing"
    },
    "oci/meta.llama-4-scout-17b-16e-instruct": {
        "max_tokens": 192000,
        "max_input_tokens": 192000,
        "max_output_tokens": 4000,
        "input_cost_per_token": 7.2e-07,
        "output_cost_per_token": 7.2e-07,
        "litellm_provider": "oci",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": false,
        "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing"
    },
    "oci/meta.llama-3.3-70b-instruct": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4000,
        "input_cost_per_token": 7.2e-07,
        "output_cost_per_token": 7.2e-07,
        "litellm_provider": "oci",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": false,
        "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing"
    },
    "oci/meta.llama-3.2-90b-vision-instruct": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4000,
        "input_cost_per_token": 2.0e-06,
        "output_cost_per_token": 2.0e-06,
        "litellm_provider": "oci",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": false,
        "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing"
    },
    "oci/meta.llama-3.1-405b-instruct": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4000,
        "input_cost_per_token": 1.068e-05,
        "output_cost_per_token": 1.068e-05,
        "litellm_provider": "oci",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": false,
        "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing"
    },

    "oci/xai.grok-4": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 3.0e-06,
        "output_cost_per_token": 1.5e-07,
        "litellm_provider": "oci",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": false,
        "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing"
    },
    "oci/xai.grok-3": {
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 3.0e-06,
        "output_cost_per_token": 1.5e-07,
        "litellm_provider": "oci",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": false,
        "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing"
    },
    "oci/xai.grok-3-mini": {
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 3.0e-07,
        "output_cost_per_token": 5.0e-07,
        "litellm_provider": "oci",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": false,
        "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing"
    },
    "oci/xai.grok-3-fast": {
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 5.0e-06,
        "output_cost_per_token": 2.5e-05,
        "litellm_provider": "oci",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": false,
        "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing"
    },
    "oci/xai.grok-3-mini-fast": {
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 6.0e-07,
        "output_cost_per_token": 4.0e-06,
        "litellm_provider": "oci",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": false,
        "supports_tool_choice": false,
        "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing"
    },

    "fireworks_ai/accounts/fireworks/models/gpt-oss-120b": {
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "source": "https://fireworks.ai/pricing"
    },
    "fireworks_ai/accounts/fireworks/models/gpt-oss-20b": {
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "source": "https://fireworks.ai/pricing"
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p1-8b-instruct": {
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "input_cost_per_token": 0.0000001, 
        "output_cost_per_token": 0.0000001,
        "litellm_provider": "fireworks_ai", 
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "source": "https://fireworks.ai/pricing",
        "supports_tool_choice": true
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v3": {
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0.0000009,
        "output_cost_per_token": 0.0000009,
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "supports_response_schema": true,
        "source": "https://fireworks.ai/pricing",
        "supports_tool_choice": true
    },

    "fireworks_ai/accounts/fireworks/models/llama-v3p2-1b-instruct": {
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384,
        "input_cost_per_token": 0.0000001, 
        "output_cost_per_token": 0.0000001,
        "litellm_provider": "fireworks_ai", 
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "source": "https://fireworks.ai/pricing",
        "supports_tool_choice": true
    },
    "fireworks_ai/accounts/admin-d353ad/deployedModels/aumogpt-7b-v1-uo8bc2by": {
        "max_tokens": 30720,
        "max_input_tokens": 30720,
        "max_output_tokens": 16384,
        "input_cost_per_token": 0.0000001, 
        "output_cost_per_token": 0.0000001,
        "litellm_provider": "fireworks_ai", 
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "source": "https://fireworks.ai/pricing",
        "supports_tool_choice": true
    },



    
    "bedrock/ai21.jamba-instruct-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 70000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 7e-07,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_system_messages": true
    },
    "bedrock/ai21.jamba-1-5-large-v1:0": {
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 8e-06,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "bedrock/ai21.jamba-1-5-mini-v1:0": {
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 4e-07,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "bedrock/amazon.titan-text-lite-v1": {
        "max_tokens": 4000,
        "max_input_tokens": 42000,
        "max_output_tokens": 4000,
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 4e-07,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "bedrock/amazon.titan-text-express-v1": {
        "max_tokens": 8000,
        "max_input_tokens": 42000,
        "max_output_tokens": 8000,
        "input_cost_per_token": 1.3e-06,
        "output_cost_per_token": 1.7e-06,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "bedrock/amazon.titan-text-premier-v1:0": {
        "max_tokens": 32000,
        "max_input_tokens": 42000,
        "max_output_tokens": 32000,
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "bedrock/mistral.mistral-7b-instruct-v0:2": {
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 2e-07,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/mistral.mixtral-8x7b-instruct-v0:1": {
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 4.5e-07,
        "output_cost_per_token": 7e-07,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/mistral.mistral-large-2402-v1:0": {
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 8e-06,
        "output_cost_per_token": 2.4e-05,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "bedrock/mistral.mistral-small-2402-v1:0": {
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 3e-06,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "bedrock/us.anthropic.claude-3-sonnet-20240229-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_pdf_input": true,
        "supports_tool_choice": true
    },
    "bedrock/us.anthropic.claude-3-5-sonnet-20240620-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_pdf_input": true,
        "supports_tool_choice": true
    },
    "bedrock/us.anthropic.claude-3-5-sonnet-20241022-v2:0": {
        "supports_computer_use": true,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_read_input_token_cost": 3e-07,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_pdf_input": true,
        "supports_assistant_prefill": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "bedrock/us.anthropic.claude-3-haiku-20240307-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 1.25e-06,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_pdf_input": true,
        "supports_tool_choice": true
    },
    "bedrock/us.anthropic.claude-3-5-haiku-20241022-v1:0": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 4e-06,
        "cache_creation_input_token_cost": 1e-06,
        "cache_read_input_token_cost": 8e-08,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_assistant_prefill": true,
        "supports_pdf_input": true,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "bedrock/us.anthropic.claude-3-opus-20240229-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_tool_choice": true
    },
    "bedrock/us.anthropic.claude-3-7-sonnet-20250219-v1:0": {
        "supports_computer_use": true,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_assistant_prefill": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_pdf_input": true,
        "supports_tool_choice": true,
        "supports_reasoning": true
    },
    "bedrock/cohere.command-text-v14": {
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.5e-06,
        "output_cost_per_token": 2e-06,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/cohere.command-light-text-v14": {
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 6e-07,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/cohere.command-r-plus-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/cohere.command-r-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/meta.llama3-8b-instruct-v1:0": {
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 6e-07,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "bedrock/meta.llama3-70b-instruct-v1:0": {
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "input_cost_per_token": 2.65e-06,
        "output_cost_per_token": 3.5e-06,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "bedrock/us.meta.llama3-1-8b-instruct-v1:0": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "input_cost_per_token": 2.2e-07,
        "output_cost_per_token": 2.2e-07,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "bedrock/us.meta.llama3-1-70b-instruct-v1:0": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "input_cost_per_token": 9.9e-07,
        "output_cost_per_token": 9.9e-07,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "bedrock/us.meta.llama3-2-1b-instruct-v1:0": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "bedrock/us.meta.llama3-2-3b-instruct-v1:0": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 1.5e-07,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "bedrock/us.meta.llama3-2-11b-instruct-v1:0": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 3.5e-07,
        "output_cost_per_token": 3.5e-07,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": false,
        "supports_vision": true
    },
    "bedrock/us.meta.llama3-2-90b-instruct-v1:0": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 2e-06,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": false,
        "supports_vision": true
    }
}