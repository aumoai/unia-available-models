{
  "providers": [
    {
      "name": "Bedrock",
      "displayName": "AWS Bedrock",
      "base_model_name": "bedrock",
      "credentials_needed": {
        "aws_region_name": {
          "type": "string",
          "displayName": "Nome da Regi찾o",
          "description": "Nome da Regi찾o da AWS. Por exemplo: us-east-1, sa-east-1, etc.",
          "required": true
        },
        "aws_access_key_id": {
          "type": "string",
          "displayName": "Access Key ID",
          "description": "AWS Access Key ID da conta com permiss찾o para usar o Bedrock. Garanta que deu as permiss천es corretas no IAM.",
          "required": true
        },
        "aws_secret_access_key": {
          "type": "string",
          "displayName": "Secret Access Key",
          "description": "Secret Access Key da AWS ",
          "required": true
        }
      },
      "models": [
        {
          "displayName": "Llama3 8B Instruct",
          "submodels": [
            "meta.llama3-8b-instruct-v1:0"
          ],
          "max_input_tokens": 8192,
          "max_output_tokens": 8192,
          "input_cost_per_token": 3e-07,
          "output_cost_per_token": 6e-07,
          "supports_function_calling": false,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Llama3 70B Instruct",
          "submodels": [
            "meta.llama3-70b-instruct-v1:0"
          ],
          "max_input_tokens": 8192,
          "max_output_tokens": 8192,
          "input_cost_per_token": 2.65e-06,
          "output_cost_per_token": 3.5e-06,
          "supports_function_calling": false,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Llama3 1-8B Instruct",
          "submodels": [
            "us.meta.llama3-1-8b-instruct-v1:0"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 2048,
          "input_cost_per_token": 2.2e-07,
          "output_cost_per_token": 2.2e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Llama3 1-70B Instruct",
          "submodels": [
            "us.meta.llama3-1-70b-instruct-v1:0"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 2048,
          "input_cost_per_token": 9.9e-07,
          "output_cost_per_token": 9.9e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Llama3 2-1B Instruct",
          "submodels": [
            "us.meta.llama3-2-1b-instruct-v1:0"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 1e-07,
          "output_cost_per_token": 1e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Llama3 2-3B Instruct",
          "submodels": [
            "us.meta.llama3-2-3b-instruct-v1:0"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 1.5e-07,
          "output_cost_per_token": 1.5e-07,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Llama3 2-90B Instruct",
          "submodels": [
            "us.meta.llama3-2-90b-instruct-v1:0"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 4096,
          "input_cost_per_token": 2e-06,
          "output_cost_per_token": 2e-06,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "OpenAI GPT OSS 120B",
          "submodels": [
            "openai.gpt-oss-120b-1:0"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 8191,
          "input_cost_per_token": 1e-6,
          "output_cost_per_token": 3e-6,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "OpenAI GPT OSS 20B",
          "submodels": [
            "openai.gpt-oss-20b-1:0"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 8191,
          "input_cost_per_token": 1e-6,
          "output_cost_per_token": 3e-6,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Qwen3 32B",
          "submodels": [
            "qwen.qwen3-32b-v1:0"
          ],
          "max_input_tokens": 16384,
          "max_output_tokens": 8191,
          "input_cost_per_token": 1.5e-7,
          "output_cost_per_token": 6e-7,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Qwen3 Coder 30B",
          "submodels": [
            "qwen.qwen3-coder-30b-a3b-v1:0"
          ],
          "max_input_tokens": 262144,
          "max_output_tokens": 8191,
          "input_cost_per_token": 1.5e-7,
          "output_cost_per_token": 6e-7,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Qwen3 Next 80B A3B",
          "submodels": [
            "qwen.qwen3-next-80b-a3b"
          ],
          "max_input_tokens": 262144,
          "max_output_tokens": 8191,
          "input_cost_per_token": 1.5e-7,
          "output_cost_per_token": 1.2e-6,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "Ministral 14B 3.0",
          "submodels": [
            "mistral.ministral-3-14b-instruct"
          ],
          "max_input_tokens": 262144,
          "max_output_tokens": 8191,
          "input_cost_per_token": 2e-7,
          "output_cost_per_token": 2e-7,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        },
        {
          "displayName": "NVIDIA Nemotron Nano 2",
          "submodels": [
            "nvidia.nemotron-nano-9b-v2"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 8191,
          "input_cost_per_token": 6e-8,
          "output_cost_per_token": 2.3e-7,
          "supports_function_calling": true,
          "supports_vision": false,
          "status": "active"
        },
        {
          "displayName": "NVIDIA Nemotron Nano 2 VL",
          "submodels": [
            "nvidia.nemotron-nano-12b-v2"
          ],
          "max_input_tokens": 128000,
          "max_output_tokens": 8191,
          "input_cost_per_token": 2e-7,
          "output_cost_per_token": 6e-7,
          "supports_function_calling": true,
          "supports_vision": true,
          "status": "active"
        }
      ]
    }
  ]
}
